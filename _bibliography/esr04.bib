@article{Moonisa:2021,
author = {Jaspe-Villanueva, Alberto and Ahsan, Moonisa and Pintus, Ruggero and Giachetti, Andrea and Marton, Fabio and Gobbetti, Enrico},
title = {Web-Based Exploration of Annotated Multi-Layered Relightable Image Models},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1556-4673},
url = {https://doi.org/10.1145/3430846},
doi = {10.1145/3430846},
abstract = {We introduce a novel approach for exploring image-based shape and material models registered with structured descriptive information fused in multi-scale overlays. We represent the objects of interest as a series of registered layers of image-based shape and material data. These layers are represented at different scales and can come out of a variety of pipelines. These layers can include both Reflectance Transformation Imaging representations, and spatially varying normal and Bidirectional Reflectance Distribution Function fields, possibly as a result of fusing multi-spectral data. An overlay image pyramid associates visual annotations to the various scales. The overlay pyramid of each layer is created at data preparation time by either one of the three subsequent methods: (1) by importing it from other pipelines, (2) by creating it with the simple annotation drawing toolkit available within the viewer, and (3) with external image editing tools. This makes it easier for the user to seamlessly draw annotations over the region of interest. At runtime, clients can access an annotated multi-layered dataset by a standard web server. Users can explore these datasets on a variety of devices; they range from small mobile devices to large-scale displays used in museum installations. On all these aforementioned platforms, JavaScript/WebGL2 clients running in browsers are fully capable of performing layer selection, interactive relighting, enhanced visualization, and annotation display. We address the problem of clutter by embedding interactive lenses. This focus-and-context-aware (multiple-layer) exploration tool supports exploration of more than one representation in a single view. That allows mixing and matching of presentation modes and annotation display. The capabilities of our approach are demonstrated on a variety of cultural heritage use-cases. That involves different kinds of annotated surface and material models.},
journal = {J. Comput. Cult. Herit.},
month = may,
articleno = {24},
numpages = {29},
keywords = {3D visualization, annotations, reflectance transformation imaging, 2D visualization}
}

@article {Bettio:2021_6,
journal = {Computer Graphics Forum},
title = {{A Novel Approach for Exploring Annotated Data With Interactive Lenses}},
author = {Bettio, Fabio and Ahsan, Moonisa and Marton, Fabio and Gobbetti, Enrico},
year = {2021},
publisher = {The Eurographics Association and John Wiley & Sons Ltd.},
ISSN = {1467-8659},
url = { https://dspace.crs4.it/jspui/handle/1138/31},
DOI = {10.1111/cgf.14315}
}

@inproceedings {10.2312:stag.20211477,
booktitle = {Smart Tools and Apps for Graphics - Eurographics Italian Chapter Conference},
editor = {Frosini, Patrizio and Giorgi, Daniela and Melzi, Simone and Rodolˆ, Emanuele},
title = {{Guiding Lens-based Exploration using Annotation Graphs}},
author = {Ahsan, Moonisa and Marton, Fabio and Pintus, Ruggero and Gobbetti, Enrico},
year = {2021},
publisher = {The Eurographics Association},
ISSN = {2617-4855},
ISBN = {978-3-03868-165-6},
DOI = {10.2312/stag.20211477},
url = {https://dspace.crs4.it/jspui/handle/1138/35 },
}