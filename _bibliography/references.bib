@article{Alderighi:2019,
author = {Alderighi, Thomas and Malomo, Luigi and Giorgi, Daniela and Bickel, Bernd and Cignoni, Paolo and Pietroni, Nico},
title = {Volume-Aware Design of Composite Molds},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://openportal.isti.cnr.it/doc?id=people______::036b4ebf5bb0d906222ec4024e0535c3},
doi = {10.1145/3306346.3322981},
abstract = {We propose a novel technique for the automatic design of molds to cast highly complex shapes. The technique generates composite, two-piece molds. Each mold piece is made up of a hard plastic shell and a flexible silicone part. Thanks to the thin, soft, and smartly shaped silicone part, which is kept in place by a hard plastic shell, we can cast objects of unprecedented complexity. An innovative algorithm based on a volumetric analysis defines the layout of the internal cuts in the silicone mold part. Our approach can robustly handle thin protruding features and intertwined topologies that have caused previous methods to fail. We compare our results with state of the art techniques, and we demonstrate the casting of shapes with extremely complex geometry.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {110},
numpages = {12},
keywords = {mold design, casting, fabrication}
}

@article{Celarek:2019,
author = {Celarek, A. and Jakob, W. and Wimmer, M. and Lehtinen, J.},
title = {Quantifying the Error of Light Transport Algorithms},
journal = {Computer Graphics Forum},
year = {2019},
volume = {38},
number = {4},
pages = {111-121},
doi = {10.1111/cgf.13775},
url = {https://repositum.tuwien.at/handle/20.500.12708/15941}
}

@article{Pintore:2020:SI3,
    author = {Giovanni Pintore and Claudio Mura and Fabio Ganovelli and Lizeth Fuentes-Perez and Renato Pajarola and Enrico Gobbetti},
    title = {State-of-the-art in Automatic 3D Reconstruction of Structured Indoor Environments},
    journal = {Computer Graphics Forum},
    volume = {39},
    number = {2},
    year = {2020},
    abstract = { Creating high-level structured 3D models of real-world indoor scenes from captured data is a fundamental task which has important applications in many fields. Given the complexity and variability of interior environments and the need to cope with noisy and partial captured data, many open research problems remain, despite the substantial progress made in the past decade. In this survey, we provide an up-to-date integrative view of the field, bridging complementary views coming from computer graphics and computer vision. After providing a characterization of input sources, we define the structure of output models and the priors exploited to bridge the gap between imperfect sources and desired output. We then identify and discuss the main components of a structured reconstruction pipeline, and review how they are combined in scalable solutions working at the building level. We finally point out relevant research issues and analyze research trends. },
    note = {To appear},
    doi = {https://doi.org/10.1111/cgf.14021},
    url = {https://dspace.crs4.it/jspui/handle/1138/12},
}
@inproceedings{PMGFPG:20b,
	Author = {Pintore, Giovanni and Mura, Claudio and Ganovelli, Fabio and Fuentes-Perez, Lizeth and Pajarola, Renato and Gobbetti, Enrico},
	Booktitle = {ACM SIGGRAPH Tutorials},
	Keywords = {graphics, architecture, 3D reconstruction, point cloud, scanning, indoor scene reconstruction, segmentation, floor plans},
	Title = {Automatic {3D} Reconstruction of Structured Indoor Environments},
  Url = {https://dspace.crs4.it/jspui/handle/1138/13},
  Doi = {https://doi.org/10.1145/3388769.3407469},
	Year = {2020}}

@article{Tausch:2020,
            Author = {Tausch, Reimar and Domajnko, Matevz and Ritz, Martin and Knuth, Martin and Santos, Pedro and Fellner, Dieter W.},
            Url = {http://publica.fraunhofer.de/documents/N-578457.html},
            Journal = {IPSI Transactions on Internet Research},
            Keywords = {{3D} data acquisition, {3D} scanning, path planning, next-best view planning, automation},
            Month = {January},
            Number = {1},
            Pages = {45--53},
            Title = {Towards 3D Digitization in the GLAM (Galleries, Libraries, Archives, and Museums) Sector: Lessons Learned and Future Outlook},
            Volume = {16},
            Year = {2020}}

@InProceedings{10.1007/978-3-030-58598-3_26,
author="Pintore, Giovanni
and Agus, Marco
and Gobbetti, Enrico",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="AtlantaNet: Inferring the 3D Indoor Layout from a Single 360 degree Image Beyond the Manhattan World Assumption",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
doi = "10.1007/978-3-030-58598-3_26",
url = "https://dspace.crs4.it/jspui/handle/1138/14",
address="Cham",
pages="432--448",
abstract="We introduce a novel end-to-end approach to predict a 3D room layout from a single panoramic image. Compared to recent state-of-the-art works, our method is not limited to Manhattan World environments, and can reconstruct rooms bounded by vertical walls that do not form right angles or are curved -- i.e., Atlanta World models. In our approach, we project the original gravity-aligned panoramic image on two horizontal planes, one above and one below the camera. This representation encodes all the information needed to recover the Atlanta World 3D bounding surfaces of the room in the form of a 2D room footprint on the floor plan and a room height. To predict the 3D layout, we propose an encoder-decoder neural network architecture, leveraging Recurrent Neural Networks (RNNs) to capture long-range geometric patterns, and exploiting a customized training strategy based on domain-specific knowledge. The experimental results demonstrate that our method outperforms state-of-the-art solutions in prediction accuracy, in particular in cases of complex wall layouts or curved wall footprints.",
isbn="978-3-030-58598-3"
}

@article{Filoscia:2020,
author = {Filoscia, I. and Alderighi, T. and Giorgi, D. and Malomo, L. and Callieri, M. and Cignoni, P.},
title = {Optimizing Object Decomposition to Reduce Visual Artifacts in 3D Printing},
journal = {Computer Graphics Forum},
volume = {39},
number = {2},
pages = {423-434},
doi = {https://doi.org/10.1111/cgf.13941},
url = {https://openportal.isti.cnr.it/doc?id=people______::9d51621aaa57ea79baa0ac0466002bf0},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13941},
abstract = {Abstract We propose a method for the automatic segmentation of 3D objects into parts which can be individually 3D printed and then reassembled by preserving the visual quality of the final object. Our technique focuses on minimizing the surface affected by supports, decomposing the object into multiple parts whose printing orientation is automatically chosen. The segmentation reduces the visual impact on the fabricated model producing non-planar cuts that adapt to the object shape. This is performed by solving an optimization problem that balances the effects of supports and cuts, while trying to place both in occluded regions of the object surface. To assess the practical impact of the solution, we show a number of segmented, 3D printed and reassembled objects.},
year = {2020}
}

@article{Laccone:2020,
	Abstract = {Bending-active structures are able to efficiently produce complex curved shapes from flat panels. The desired deformation of the panels derives from the proper selection of their elastic properties. Optimized panels, called FlexMaps, are designed such that, once they are bent and assembled, the resulting static equilibrium configuration matches a desired input 3D shape. The FlexMaps elastic properties are controlled by locally varying spiraling geometric mesostructures, which are optimized in size and shape to match specific bending requests, namely the global curvature of the target shape. The design pipeline starts from a quad mesh representing the input 3D shape, which defines the edge size and the total amount of spirals: every quad will embed one spiral. Then, an optimization algorithm tunes the geometry of the spirals by using a simplified pre-computed rod model. This rod model is derived from a non-linear regression algorithm which approximates the non-linear behavior of solid FEM spiral models subject to hundreds of load combinations. This innovative pipeline has been applied to the project of a lightweight plywood pavilion named FlexMaps Pavilion, which is a single-layer piecewise twisted arch that fits a bounding box of 3.90x3.96x3.25 meters. This case study serves to test the applicability of this methodology at the architectural scale. The structure is validated via FE analyses and the fabrication of the full scale prototype.},
	Author = {Laccone, Francesco and Malomo, Luigi and P{\'e}rez, Jes{\'u}s and Pietroni, Nico and Ponchio, Federico and Bickel, Bernd and Cignoni, Paolo},
	Da = {2020/08/12},
	Date-Added = {2020-11-11 9:21:41 PM +0100},
	Date-Modified = {2020-11-11 9:21:41 PM +0100},
	Doi = {10.1007/s42452-020-03305-w},
	Id = {Laccone2020},
	Isbn = {2523-3971},
	Journal = {SN Applied Sciences},
	Number = {9},
	Pages = {1505},
	Title = {A bending-active twisted-arch plywood structure: computational design and fabrication of the FlexMaps Pavilion},
	Ty = {JOUR},
	Url = {https://openportal.isti.cnr.it/doc?id=people______::67e43779f306d8fc3f362f80a56265a1},
	Volume = {2},
	Year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1007/s42452-020-03305-w}}

@inproceedings{FRMMP:20,
	author = {Fuentes Perez, Lizeth J. and Romero Calla, Luciano A. and Montenegro, Anselmo A. and Mura, Claudio and Pajarola, Renato},
	booktitle = {Proceedings of Pacific Graphics Short Papers},
	doi = {https://doi.org/10.2312/pg.20201226},
  url = {https://www.zora.uzh.ch/id/eprint/193666/},
	keywords = {graphics, geometry processing},
	pages = {25--30},
	title = {A Robust Feature-aware Sparse Mesh Representation},
	year = {2020}}  

@article{chen29deep,
  title={Deep learning models for optically characterizing 3D printers},
  author={Chen, Danwu and Urban, Philipp},
  journal={Optics Express},
  volume={29},
  month = {Jan},
  number={2},
  pages={615--631},
  url = {http://publica.fraunhofer.de/documents/N-621396.html},
  doi = {10.1364/OE.410796},
  publisher={Optical Society of America},
  year = {2021}
}

@article{Moonisa:2021,
author = {Jaspe-Villanueva, Alberto and Ahsan, Moonisa and Pintus, Ruggero and Giachetti, Andrea and Marton, Fabio and Gobbetti, Enrico},
title = {Web-Based Exploration of Annotated Multi-Layered Relightable Image Models},
year = {2021},
issue_date = {May 2021},
month = {Jan},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1556-4673},
url = {https://doi.org/10.1145/3430846},
doi = {10.1145/3430846},
abstract = {We introduce a novel approach for exploring image-based shape and material models registered with structured descriptive information fused in multi-scale overlays. We represent the objects of interest as a series of registered layers of image-based shape and material data. These layers are represented at different scales and can come out of a variety of pipelines. These layers can include both Reflectance Transformation Imaging representations, and spatially varying normal and Bidirectional Reflectance Distribution Function fields, possibly as a result of fusing multi-spectral data. An overlay image pyramid associates visual annotations to the various scales. The overlay pyramid of each layer is created at data preparation time by either one of the three subsequent methods: (1) by importing it from other pipelines, (2) by creating it with the simple annotation drawing toolkit available within the viewer, and (3) with external image editing tools. This makes it easier for the user to seamlessly draw annotations over the region of interest. At runtime, clients can access an annotated multi-layered dataset by a standard web server. Users can explore these datasets on a variety of devices; they range from small mobile devices to large-scale displays used in museum installations. On all these aforementioned platforms, JavaScript/WebGL2 clients running in browsers are fully capable of performing layer selection, interactive relighting, enhanced visualization, and annotation display. We address the problem of clutter by embedding interactive lenses. This focus-and-context-aware (multiple-layer) exploration tool supports exploration of more than one representation in a single view. That allows mixing and matching of presentation modes and annotation display. The capabilities of our approach are demonstrated on a variety of cultural heritage use-cases. That involves different kinds of annotated surface and material models.},
journal = {J. Comput. Cult. Herit.},
month = may,
articleno = {24},
numpages = {29},
keywords = {3D visualization, annotations, reflectance transformation imaging, 2D visualization}
}