@article{Alderighi:2019,
author = {Alderighi, Thomas and Malomo, Luigi and Giorgi, Daniela and Bickel, Bernd and Cignoni, Paolo and Pietroni, Nico},
title = {Volume-Aware Design of Composite Molds},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://openportal.isti.cnr.it/doc?id=people______::036b4ebf5bb0d906222ec4024e0535c3},
doi = {10.1145/3306346.3322981},
abstract = {We propose a novel technique for the automatic design of molds to cast highly complex shapes. The technique generates composite, two-piece molds. Each mold piece is made up of a hard plastic shell and a flexible silicone part. Thanks to the thin, soft, and smartly shaped silicone part, which is kept in place by a hard plastic shell, we can cast objects of unprecedented complexity. An innovative algorithm based on a volumetric analysis defines the layout of the internal cuts in the silicone mold part. Our approach can robustly handle thin protruding features and intertwined topologies that have caused previous methods to fail. We compare our results with state of the art techniques, and we demonstrate the casting of shapes with extremely complex geometry.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {110},
numpages = {12},
keywords = {mold design, casting, fabrication}
}

@article{Celarek:2019,
author = {Celarek, A. and Jakob, W. and Wimmer, M. and Lehtinen, J.},
title = {Quantifying the Error of Light Transport Algorithms},
journal = {Computer Graphics Forum},
year = {2019},
volume = {38},
number = {4},
pages = {111-121},
doi = {10.1111/cgf.13775},
url = {https://repositum.tuwien.at/handle/20.500.12708/15941}
}

@article{Pintore:2020:SI3,
    author = {Giovanni Pintore and Claudio Mura and Fabio Ganovelli and Lizeth Fuentes-Perez and Renato Pajarola and Enrico Gobbetti},
    title = {State-of-the-art in Automatic 3D Reconstruction of Structured Indoor Environments},
    journal = {Computer Graphics Forum},
    volume = {39},
    number = {2},
    year = {2020},
    abstract = { Creating high-level structured 3D models of real-world indoor scenes from captured data is a fundamental task which has important applications in many fields. Given the complexity and variability of interior environments and the need to cope with noisy and partial captured data, many open research problems remain, despite the substantial progress made in the past decade. In this survey, we provide an up-to-date integrative view of the field, bridging complementary views coming from computer graphics and computer vision. After providing a characterization of input sources, we define the structure of output models and the priors exploited to bridge the gap between imperfect sources and desired output. We then identify and discuss the main components of a structured reconstruction pipeline, and review how they are combined in scalable solutions working at the building level. We finally point out relevant research issues and analyze research trends. },
    note = {To appear},
    doi = {https://doi.org/10.1111/cgf.14021},
    url = {https://dspace.crs4.it/jspui/handle/1138/12},
}
@inproceedings{PMGFPG:20b,
	Author = {Pintore, Giovanni and Mura, Claudio and Ganovelli, Fabio and Fuentes-Perez, Lizeth and Pajarola, Renato and Gobbetti, Enrico},
	Booktitle = {ACM SIGGRAPH Tutorials},
	Keywords = {graphics, architecture, 3D reconstruction, point cloud, scanning, indoor scene reconstruction, segmentation, floor plans},
	Title = {Automatic {3D} Reconstruction of Structured Indoor Environments},
  Url = {https://dspace.crs4.it/jspui/handle/1138/13},
  Doi = {https://doi.org/10.1145/3388769.3407469},
	Year = {2020}}

@article{Tausch:2020,
            Author = {Tausch, Reimar and Domajnko, Matevz and Ritz, Martin and Knuth, Martin and Santos, Pedro and Fellner, Dieter W.},
            Url = {http://publica.fraunhofer.de/documents/N-578457.html},
            Journal = {IPSI Transactions on Internet Research},
            Keywords = {{3D} data acquisition, {3D} scanning, path planning, next-best view planning, automation},
            Month = {January},
            Number = {1},
            Pages = {45--53},
            Title = {Towards 3D Digitization in the GLAM (Galleries, Libraries, Archives, and Museums) Sector: Lessons Learned and Future Outlook},
            Volume = {16},
            Year = {2020}}

@InProceedings{10.1007/978-3-030-58598-3_26,
author="Pintore, Giovanni
and Agus, Marco
and Gobbetti, Enrico",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="AtlantaNet: Inferring the 3D Indoor Layout from a Single 360 degree Image Beyond the Manhattan World Assumption",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
doi = "10.1007/978-3-030-58598-3_26",
url = "https://dspace.crs4.it/jspui/handle/1138/14",
address="Cham",
pages="432--448",
abstract="We introduce a novel end-to-end approach to predict a 3D room layout from a single panoramic image. Compared to recent state-of-the-art works, our method is not limited to Manhattan World environments, and can reconstruct rooms bounded by vertical walls that do not form right angles or are curved -- i.e., Atlanta World models. In our approach, we project the original gravity-aligned panoramic image on two horizontal planes, one above and one below the camera. This representation encodes all the information needed to recover the Atlanta World 3D bounding surfaces of the room in the form of a 2D room footprint on the floor plan and a room height. To predict the 3D layout, we propose an encoder-decoder neural network architecture, leveraging Recurrent Neural Networks (RNNs) to capture long-range geometric patterns, and exploiting a customized training strategy based on domain-specific knowledge. The experimental results demonstrate that our method outperforms state-of-the-art solutions in prediction accuracy, in particular in cases of complex wall layouts or curved wall footprints.",
isbn="978-3-030-58598-3"
}

@article{Filoscia:2020,
author = {Filoscia, I. and Alderighi, T. and Giorgi, D. and Malomo, L. and Callieri, M. and Cignoni, P.},
title = {Optimizing Object Decomposition to Reduce Visual Artifacts in 3D Printing},
journal = {Computer Graphics Forum},
volume = {39},
number = {2},
pages = {423-434},
doi = {https://doi.org/10.1111/cgf.13941},
url = {https://openportal.isti.cnr.it/doc?id=people______::9d51621aaa57ea79baa0ac0466002bf0},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13941},
abstract = {Abstract We propose a method for the automatic segmentation of 3D objects into parts which can be individually 3D printed and then reassembled by preserving the visual quality of the final object. Our technique focuses on minimizing the surface affected by supports, decomposing the object into multiple parts whose printing orientation is automatically chosen. The segmentation reduces the visual impact on the fabricated model producing non-planar cuts that adapt to the object shape. This is performed by solving an optimization problem that balances the effects of supports and cuts, while trying to place both in occluded regions of the object surface. To assess the practical impact of the solution, we show a number of segmented, 3D printed and reassembled objects.},
year = {2020}
}

@article{Laccone:2020,
	Abstract = {Bending-active structures are able to efficiently produce complex curved shapes from flat panels. The desired deformation of the panels derives from the proper selection of their elastic properties. Optimized panels, called FlexMaps, are designed such that, once they are bent and assembled, the resulting static equilibrium configuration matches a desired input 3D shape. The FlexMaps elastic properties are controlled by locally varying spiraling geometric mesostructures, which are optimized in size and shape to match specific bending requests, namely the global curvature of the target shape. The design pipeline starts from a quad mesh representing the input 3D shape, which defines the edge size and the total amount of spirals: every quad will embed one spiral. Then, an optimization algorithm tunes the geometry of the spirals by using a simplified pre-computed rod model. This rod model is derived from a non-linear regression algorithm which approximates the non-linear behavior of solid FEM spiral models subject to hundreds of load combinations. This innovative pipeline has been applied to the project of a lightweight plywood pavilion named FlexMaps Pavilion, which is a single-layer piecewise twisted arch that fits a bounding box of 3.90x3.96x3.25 meters. This case study serves to test the applicability of this methodology at the architectural scale. The structure is validated via FE analyses and the fabrication of the full scale prototype.},
	Author = {Laccone, Francesco and Malomo, Luigi and P{\'e}rez, Jes{\'u}s and Pietroni, Nico and Ponchio, Federico and Bickel, Bernd and Cignoni, Paolo},
	Da = {2020/08/12},
	Date-Added = {2020-11-11 9:21:41 PM +0100},
	Date-Modified = {2020-11-11 9:21:41 PM +0100},
	Doi = {10.1007/s42452-020-03305-w},
	Id = {Laccone2020},
	Isbn = {2523-3971},
	Journal = {SN Applied Sciences},
	Number = {9},
	Pages = {1505},
	Title = {A bending-active twisted-arch plywood structure: computational design and fabrication of the FlexMaps Pavilion},
	Ty = {JOUR},
	Url = {https://openportal.isti.cnr.it/doc?id=people______::67e43779f306d8fc3f362f80a56265a1},
	Volume = {2},
	Year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1007/s42452-020-03305-w}}

@inproceedings{FRMMP:20,
	author = {Fuentes Perez, Lizeth J. and Romero Calla, Luciano A. and Montenegro, Anselmo A. and Mura, Claudio and Pajarola, Renato},
	booktitle = {Proceedings of Pacific Graphics Short Papers},
	doi = {https://doi.org/10.2312/pg.20201226},
  url = {https://www.zora.uzh.ch/id/eprint/193666/},
	keywords = {graphics, geometry processing},
	pages = {25--30},
	title = {A Robust Feature-aware Sparse Mesh Representation},
	year = {2020}}  

@article{chen29deep,
  title={Deep learning models for optically characterizing 3D printers},
  author={Chen, Danwu and Urban, Philipp},
  journal={Optics Express},
  volume={29},
  month = {jan},
  number={2},
  pages={615--631},
  url = {http://publica.fraunhofer.de/documents/N-621396.html},
  doi = {10.1364/OE.410796},
  publisher={Optical Society of America},
  year = {2021}
}

@article{Ahsan:2021,
author = {Jaspe-Villanueva, Alberto and Ahsan, Moonisa and Pintus, Ruggero and Giachetti, Andrea and Marton, Fabio and Gobbetti, Enrico},
title = {Web-Based Exploration of Annotated Multi-Layered Relightable Image Models},
month = {may},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1556-4673},
url = {https://doi.org/10.1145/3430846},
doi = {10.1145/3430846},
journal = {Journal on Computing and Cultural Heritage},
articleno = {24},
numpages = {29},
year = {2021}
}

@inproceedings{Mary:2021_1,
author = {Mary Guindy and Attila Barsi and Peter A. Kara and Tibor Balogh and Aniko Simon},
title = {{Interaction methods for light field displays by means of a theater model environment}},
volume = {11774},
booktitle = {Holography: Advances and Modern Trends VII},
editor = {Antonio Fimia and Miroslav Hrabovský and John T. Sheridan},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {109 -- 118},
keywords = {Light field, User interface, 3D rendering, Light field visualization},
year = {2021},
month = {apr},
doi = {10.1117/12.2589126},
URL = {https://doi.org/10.1117/12.2589126}
}

@inproceedings{Mary:2021_2,
author = {Mary Guindy and Attila Barsi and Peter A. Kara and Tibor Balogh and Aniko Simon},
title = {{Realistic physical camera motion for light field visualization}},
volume = {11774},
booktitle = {Holography: Advances and Modern Trends VII},
editor = {Antonio Fimia and Miroslav Hrabovský and John T. Sheridan},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {70 -- 77},
keywords = {Light field, Virtual cameras,  Physical camera simulation, Camera motion, Cinematography},
year = {2021},
month = {apr},
doi = {10.1117/12.2589128},
URL = {https://doi.org/10.1117/12.2589128}
}

@inproceedings{Mary:2021_3,
author = {Mary Guindy and Attila Barsi and Peter A. Kara and Tibor Balogh and Aniko Simon},
title = {{On the simulation of hand-held cameras in light-field rendering}},
volume = {11774},
booktitle = {Holography: Advances and Modern Trends VII},
editor = {Antonio Fimia and Miroslav Hrabovský and John T. Sheridan},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {119 -- 124},
keywords = {Light field, Hand-held cameras, Camera motion, Camera motion path, 3D rendering},
year = {2021},
month = {apr},
doi = {10.1117/12.2589129},
URL = {https://doi.org/10.1117/12.2589129}
}

@inproceedings{Cardoso:2021_4,
  author={Joao Afonso Cardoso and Nuno Goncalves and Michael Wimmer},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={Cost Volume Refinement for Depth Prediction}, 
  year={2021},
  month={jan},
  pages={354 -- 361},
  doi={10.1109/ICPR48806.2021.9412730},
  URL={https://doi.org/10.1109/ICPR48806.2021.9412730}}

@article {Bettio:2021_6,
journal = {Computer Graphics Forum},
title = {{A Novel Approach for Exploring Annotated Data With Interactive Lenses}},
author = {Bettio, Fabio and Ahsan, Moonisa and Marton, Fabio and Gobbetti, Enrico},
year = {2021},
publisher = {The Eurographics Association and John Wiley & Sons Ltd.},
ISSN = {1467-8659},
url = { https://dspace.crs4.it/jspui/handle/1138/31},
DOI = {10.1111/cgf.14315}
}

@inproceedings{Balogh:2021_7,
author = {Tibor Balogh and Attila Barsi and Peter A. Kara and Mary Guindy and Aniko Simon and Zsolt Nagy},
title = {{3D light field LED wall}},
volume = {11788},
booktitle = {Digital Optical Technologies 2021},
editor = {Bernard C. Kress and Christophe Peroz},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {180 -- 190},
keywords = {3D light field, novel system design, LED, lens array, modular display},
year = {2021},
doi = {https://doi.org/10.1117/12.2594276},
URL = {https://doi.org/10.1117/12.2594276}
}
@inproceedings{Peter:2021_8,
author = {Peter  A. Kara and Attila Barsi and Roopak R. Tamboli and Mary Guindy and Maria G. Martini and Tibor Balogh and Aniko Simon},
title = {{Recommendations on the viewing distance of light field displays}},
volume = {11788},
booktitle = {Digital Optical Technologies 2021},
editor = {Bernard C. Kress and Christophe Peroz},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {166 -- 179},
keywords = {light field, 3D perception, viewing conditions, key performance indicators, user-centric design},
year = {2021},
doi = {https://doi.org/10.1117/12.2594266},
URL = {https://doi.org/10.1117/12.2594266}
}

@InProceedings{Pintore:2021_CVPR,
    author    = {Pintore, Giovanni and Agus, Marco and Almansa, Eva and Schneider, Jens and Gobbetti, Enrico},
    title     = {SliceNet: Deep Dense Depth Estimation From a Single Indoor Panorama Using a Slice-Based Representation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {11536-11545},
    URL = {https://dspace.crs4.it/jspui/handle/1138/32}
}
@Article{Pintore:2021:GAR, 
    author = {Giovanni Pintore and Eva Almansa and Marco Agus and Enrico Gobbetti},
    title = {{Deep3DLayout}: {3D} Reconstruction of an Indoor Layout from a Spherical Panoramic Image},
    journal = {ACM Transactions on Graphics},
    volume = {40},
    number = {6},
    pages = {250:1--250:12},
    month = {December},
    year = {2021},
    doi = {10.1145/3478513.3480480},
    note = {Proc. SIGGRAPH Asia 2021. To appear},
    url = {http://vic.crs4.it/vic/cgi-bin/bib-page.cgi?id='Pintore:2021:GAR'},
}

@inproceedings {10.2312:stag.20211477,
booktitle = {Smart Tools and Apps for Graphics - Eurographics Italian Chapter Conference},
editor = {Frosini, Patrizio and Giorgi, Daniela and Melzi, Simone and Rodola, Emanuele},
title = {{Guiding Lens-based Exploration using Annotation Graphs}},
author = {Ahsan, Moonisa and Marton, Fabio and Pintus, Ruggero and Gobbetti, Enrico},
year = {2021},
publisher = {The Eurographics Association},
ISSN = {2617-4855},
ISBN = {978-3-03868-165-6},
DOI = {10.2312/stag.20211477},
url = {https://dspace.crs4.it/jspui/handle/1138/35 },
}

@article{MOHANTO2021,
title = {An integrative view of foveated rendering},
journal = {Computers & Graphics},
year = {2021},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2021.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0097849321002211},
author = {Bipul Mohanto and ABM Tariqul Islam and Enrico Gobbetti and Oliver Staadt},
keywords = {Foveated rendering, Gaze-contingent rendering, Adaptive resolution, Geometric simplification, Shading simplification, Chromatic degradation, Spatio-temporal deterioration},
abstract = {Foveated rendering adapts the image synthesis process to the user’s gaze. By exploiting the human visual system’s limitations, in particular in terms of reduced acuity in peripheral vision, it strives to deliver high-quality visual experiences at very reduced computational, storage, and transmission costs. Despite the very substantial progress made in the past decades, the solution landscape is still fragmented, and several research problems remain open. In this work, we present an up-to-date integrative view of the domain from the point of view of the rendering methods employed, discussing general characteristics, commonalities, differences, advantages, and limitations. We cover, in particular, techniques based on adaptive resolution, geometric simplification, shading simplification, chromatic degradation, as well spatio-temporal deterioration. Next, we review the main areas where foveated rendering is already in use today. We finally point out relevant research issues and analyze research trends.}
}