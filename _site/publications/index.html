<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Publications - EVOCATION</title>
<meta name="description" content="A Horizon 2020 Marie Skłodowska-Curie Actions Innovative Training Network">


  <meta name="author" content="EVOCATION">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="EVOCATION">
<meta property="og:title" content="Publications">
<meta property="og:url" content="http://localhost:4000/publications/">


  <meta property="og:description" content="A Horizon 2020 Marie Skłodowska-Curie Actions Innovative Training Network">











  

  


<link rel="canonical" href="http://localhost:4000/publications/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "EVOCATION: A MSCA-ITN",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="EVOCATION Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-logo" href="/"><img src="/assets/images/logo_evocation.png"></a>
        <a class="site-title" href="/">EVOCATION</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/" >Home</a>
            </li><li class="masthead__menu-item">
              <a href="/about/" >About</a>
            </li><li class="masthead__menu-item">
              <a href="/consortium/" >Consortium</a>
            </li><li class="masthead__menu-item">
              <a href="/team/" >Team</a>
            </li><li class="masthead__menu-item">
              <a href="/publications/" >Publications</a>
            </li><li class="masthead__menu-item">
              <a href="/news/" >News</a>
            </li><li class="masthead__menu-item">
              <a href="/events/" >Events</a>
            </li><li class="masthead__menu-item">
              <a href="/videos/" >Videos</a>
            </li><li class="masthead__menu-item">
              <a href="/recruitment/" >Recruitment</a>
            </li><li class="masthead__menu-item">
              <a href="/contact/" >Contact</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  

  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Publications">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/publications/" class="u-url" itemprop="url">Publications
</a>
          </h1>
          


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
        <ol class="bibliography"><li><span id="Tarek:2023_2"><span style="font-variant: small-caps">Haila, T.A., Tausch, R., Ritz, M., Santos, P., and Fellner, D.</span> 2023. A cross-polarization as a possible cause for color shift in illumination. <i>Electronic Imaging</i> <i>35</i>.</span>

<div id="Tarek:2023_2-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Tarek:2023_2-bibtex')">BibTeX</a></li>
    <div id="Tarek:2023_2-bibtex" style="display:none;">
    <pre class="collapse">@article{Tarek:2023_2,
  author = {Haila, Tarek Abu and Tausch, Reimar and Ritz, Martin and Santos, Pedro and Fellner, Dieter},
  title = {A cross-polarization as a possible cause for color shift in illumination},
  journal = {Electronic Imaging},
  volume = {35},
  year = {2023},
  publisher = {Society for Imaging Science and Technology},
  doi = {https://doi.org/10.2352/EI.2023.35.15.COLOR-192},
  url = {https://doi.org/10.2352/EI.2023.35.15.COLOR-192}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.2352/EI.2023.35.15.COLOR-192">https://doi.org/10.2352/EI.2023.35.15.COLOR-192</a></li>
    
    
      <li><a href="https://doi.org/10.2352/EI.2023.35.15.COLOR-192">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1145/3593428"><span style="font-variant: small-caps">Pintus, R., Ahsan, M., Zorcolo, A., Bettio, F., Marton, F., and Gobbetti, E.</span> 2023. Exploiting Local Shape and Material Similarity for Effective SV-BRDF Reconstruction from Sparse Multi-Light Image Collections. <i>J. Comput. Cult. Herit.</i> <i>16</i>, 2.</span>

<div id="10.1145/3593428-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#10.1145/3593428-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1145/3593428-bibtex')">BibTeX</a></li>
    <div id="10.1145/3593428-bibtex" style="display:none;">
    <pre class="collapse">@article{10.1145/3593428,
  author = {Pintus, Ruggero and Ahsan, Moonisa and Zorcolo, Antonio and Bettio, Fabio and Marton, Fabio and Gobbetti, Enrico},
  title = {Exploiting Local Shape and Material Similarity for Effective SV-BRDF Reconstruction from Sparse Multi-Light Image Collections},
  year = {2023},
  issue_date = {June 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {16},
  number = {2},
  issn = {1556-4673},
  url = {https://doi.org/10.1145/3593428},
  doi = {10.1145/3593428},
  journal = {J. Comput. Cult. Herit.},
  month = jun,
  articleno = {39},
  numpages = {31},
  keywords = {bas-reliefs, BRDF fitting, MLIC, virtual relighting, reflectance computation, paintings}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1145/3593428">10.1145/3593428</a></li>
    
    
      <li><a href="https://doi.org/10.1145/3593428">URL</a></li>
    
  </ul>

  <!--
  <p id="10.1145/3593428-abstract" class="collapse">We present a practical solution to create a relightable model from small Multi-light Image Collections (MLICs) acquired using standard acquisition pipelines. The approach targets the difficult but very common situation in which the optical behavior of a flat, but visually and geometrically rich object, such as a painting or a bas relief, is measured using a fixed camera taking a limited number of images with a different local illumination. By exploiting information from neighboring pixels through a carefully-crafted weighting and regularization scheme, we are able to efficiently infer subtle and visually pleasing per-pixel analytical Bidirectional Reflectance Distribution Functions (BRDFs) representations from few per-pixel samples. The method has a low memory footprint and is easily parallelizable. We qualitatively and quantitatively evaluated it on both synthetic and real data in the scope of image-based relighting applications.</p>
  -->

</div></li>
<li><span id="Pintore:2023:DPD"><span style="font-variant: small-caps">Pintore, G., Almansa, E., Sanchez, A., Vassena, G., and Gobbetti, E.</span> 2023. Deep Panoramic Depth Prediction and Completion for Indoor Scenes. <i>Computational Visual Media</i>.</span>

<div id="Pintore:2023:DPD-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#Pintore:2023:DPD-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Pintore:2023:DPD-bibtex')">BibTeX</a></li>
    <div id="Pintore:2023:DPD-bibtex" style="display:none;">
    <pre class="collapse">@article{Pintore:2023:DPD,
  author = {Pintore, Giovanni and Almansa, Eva and Sanchez, Armando and Vassena, Giorgio and Gobbetti, Enrico},
  title = {Deep Panoramic Depth Prediction and Completion for Indoor Scenes},
  journal = {Computational Visual Media},
  year = {2023},
  note = {To appear},
  url = {http://vic.crs4.it/vic/cgi-bin/bib-page.cgi?id='Pintore:2023:DPD'}
}
</pre>
    </div>-->

    
    
    
      <li><a href="http://vic.crs4.it/vic/cgi-bin/bib-page.cgi?id=’Pintore:2023:DPD’">URL</a></li>
    
  </ul>

  <!--
  <p id="Pintore:2023:DPD-abstract" class="collapse"> We introduce a novel end-to-end deep learning solution for rapidly estimating a dense spherical depth map of an indoor environment. Our input is a single equirectangular image registered with a sparse depth map, as provided by a variety of common capture setups. Depth is inferred by an efficient and lightweight single-branch network, which employs a dynamic gating system to process together dense visual data and sparse geometric data. We exploit the characteristics of typical man-made environments to efficiently compress multi-resolution features and find short- and long-range relations among scene parts. Furthermore, we introduce a new augmentation strategy to make the model robust to different types of sparsity, including those generated by various structured light sensors and LiDAR setups. The experimental results demonstrate that our method provides interactive performance and outperforms state-of-the-art solutions in computational efficiency, adaptivity to variable depth sparsity patterns, and prediction accuracy for challenging indoor data, even when trained solely on synthetic data without any fine tuning. </p>
  -->

</div></li>
<li><span id="Chen:23"><span style="font-variant: small-caps">Chen, D. and Urban, P.</span> 2023. Multi-printer learning framework for efficient optical printer characterization. <i>Opt. Express</i> <i>31</i>, 8, 13486–13502.</span>

<div id="Chen:23-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#Chen:23-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Chen:23-bibtex')">BibTeX</a></li>
    <div id="Chen:23-bibtex" style="display:none;">
    <pre class="collapse">@article{Chen:23,
  author = {Chen, Danwu and Urban, Philipp},
  journal = {Opt. Express},
  keywords = {Color difference; Neural networks; Optical properties; Radiative transfer; Refractive index; Transparency},
  number = {8},
  pages = {13486--13502},
  publisher = {Optica Publishing Group},
  title = {Multi-printer learning framework for efficient optical printer characterization},
  volume = {31},
  month = apr,
  year = {2023},
  url = {https://opg.optica.org/oe/abstract.cfm?URI=oe-31-8-13486},
  doi = {10.1364/OE.487526}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1364/OE.487526">10.1364/OE.487526</a></li>
    
    
      <li><a href="https://opg.optica.org/oe/abstract.cfm?URI=oe-31-8-13486">URL</a></li>
    
  </ul>

  <!--
  <p id="Chen:23-abstract" class="collapse">A high prediction accuracy of optical printer models is a prerequisite for accurately reproducing visual attributes (color, gloss, translucency) in multimaterial 3D printing. Recently, deep-learning-based models have been proposed, requiring only a moderate number of printed and measured training samples to reach a very high prediction accuracy. In this paper, we present a multi-printer deep learning (MPDL) framework that further improves data efficiency utilizing supporting data from other printers. Experiments on eight multi-material 3D printers demonstrate that the proposed framework can significantly reduce the number of training samples thus the overall printing and measurement efforts. This makes it economically feasible to frequently characterize 3D printers to achieve a high optical reproduction accuracy consistent across different printers and over time, which is crucial for color- and translucency-critical applications.</p>
  -->

</div></li>
<li><span id="RMPS:23"><span style="font-variant: small-caps">Romero Calla, L.A., Mohanto, B., Pajarola, R., and Staadt, O.</span> 2023. Multi-Display Ray Tracing Framework. <i>Posters Eurographics Conference</i>.</span>

<div id="RMPS:23-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('RMPS:23-bibtex')">BibTeX</a></li>
    <div id="RMPS:23-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{RMPS:23,
  author = {Romero Calla, Luciano A. and Mohanto, Bipul and Pajarola, Renato and Staadt, Oliver},
  booktitle = {Posters Eurographics Conference},
  keywords = {graphics, parallel rendering, ray casting},
  title = {Multi-Display Ray Tracing Framework},
  year = {2023}
}
</pre>
    </div>-->

    
    
    
  </ul>

  <!---->

</div></li>
<li><span id="9878246"><span style="font-variant: small-caps">Pintore, G., Agus, M., Almansa, E., and Gobbetti, E.</span> 2022. Instant Automatic Emptying of Panoramic Indoor Scenes. <i>IEEE Transactions on Visualization and Computer Graphics</i> <i>28</i>, 11, 3629–3639.</span>

<div id="9878246-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('9878246-bibtex')">BibTeX</a></li>
    <div id="9878246-bibtex" style="display:none;">
    <pre class="collapse">@article{9878246,
  author = {Pintore, Giovanni and Agus, Marco and Almansa, Eva and Gobbetti, Enrico},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title = {Instant Automatic Emptying of Panoramic Indoor Scenes},
  year = {2022},
  volume = {28},
  number = {11},
  pages = {3629-3639},
  doi = {10.1109/TVCG.2022.3202999}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1109/TVCG.2022.3202999">10.1109/TVCG.2022.3202999</a></li>
    
    
  </ul>

  <!---->

</div></li>
<li><span id="armando_arturo_sanchez_alcazar_2022_6367381"><span style="font-variant: small-caps">Alcazar, A.A.S., Pintore, G., and Sgrenzaroli, M.</span> 2022. Indoor3Dmapping dataset. https://doi.org/10.5281/zenodo.6367381.</span>

<div id="armando_arturo_sanchez_alcazar_2022_6367381-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('armando_arturo_sanchez_alcazar_2022_6367381-bibtex')">BibTeX</a></li>
    <div id="armando_arturo_sanchez_alcazar_2022_6367381-bibtex" style="display:none;">
    <pre class="collapse">@dataset{armando_arturo_sanchez_alcazar_2022_6367381,
  author = {Alcazar, Armando Arturo Sanchez and Pintore, Giovanni and Sgrenzaroli, Matteo},
  title = {Indoor3Dmapping dataset},
  month = mar,
  year = {2022},
  publisher = {Zenodo},
  version = {0.1.0},
  doi = {10.5281/zenodo.6367381},
  url = {https://doi.org/10.5281/zenodo.6367381}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.5281/zenodo.6367381">10.5281/zenodo.6367381</a></li>
    
    
      <li><a href="https://doi.org/10.5281/zenodo.6367381">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="celarek-2022-gmcn"><span style="font-variant: small-caps">Celarek, A., Hermosilla, P., Kerbl, B., Ropinski, T., and Wimmer, M.</span> 2022. Gaussian Mixture Convolution Networks. <i>The Tenth International Conference on Learning
               Representations (ICLR 2022)</i>, OpenReview.org, 1–23.</span>

<div id="celarek-2022-gmcn-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('celarek-2022-gmcn-bibtex')">BibTeX</a></li>
    <div id="celarek-2022-gmcn-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{celarek-2022-gmcn,
  title = {Gaussian Mixture Convolution Networks},
  author = {Celarek, Adam and Hermosilla, Pedro and Kerbl, Bernhard and Ropinski, Timo and Wimmer, Michael},
  year = {2022},
  month = apr,
  booktitle = {The Tenth International Conference on Learning
                 Representations (ICLR 2022)},
  event = {ICLR | 2022},
  publisher = {OpenReview.org},
  pages = {1--23},
  doi = {https://doi.org/10.48550/arXiv.2202.09153},
  url = {https://www.cg.tuwien.ac.at/research/publications/2022/celarek-2022-gmcn/}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.48550/arXiv.2202.09153">https://doi.org/10.48550/arXiv.2202.09153</a></li>
    
    
      <li><a href="https://www.cg.tuwien.ac.at/research/publications/2022/celarek-2022-gmcn/">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Chen:22"><span style="font-variant: small-caps">Chen, D. and Urban, P.</span> 2022. Inducing robustness and plausibility in deep learning optical 3D printer models. <i>Opt. Express</i> <i>30</i>, 11, 18119–18133.</span>

<div id="Chen:22-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Chen:22-bibtex')">BibTeX</a></li>
    <div id="Chen:22-bibtex" style="display:none;">
    <pre class="collapse">@article{Chen:22,
  author = {Chen, Danwu and Urban, Philipp},
  journal = {Opt. Express},
  keywords = {Image metrics; Neural networks; Optical properties; Radiative transfer; Stochastic processes; Transparency},
  number = {11},
  pages = {18119--18133},
  publisher = {OSA},
  title = {Inducing robustness and plausibility in deep learning optical 3D printer models},
  volume = {30},
  month = may,
  year = {2022},
  url = {http://opg.optica.org/oe/abstract.cfm?URI=oe-30-11-18119},
  doi = {10.1364/OE.455115}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1364/OE.455115">10.1364/OE.455115</a></li>
    
    
      <li><a href="http://opg.optica.org/oe/abstract.cfm?URI=oe-30-11-18119">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Moonisa:2022"><span style="font-variant: small-caps">Ahsan, M., Marton, F., Pintus, R., and Gobbetti, E.</span> 2022. Audio-visual annotation graphs for guiding lens-based scene exploration. <i>Computers &amp; Graphics</i>.</span>

<div id="Moonisa:2022-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Moonisa:2022-bibtex')">BibTeX</a></li>
    <div id="Moonisa:2022-bibtex" style="display:none;">
    <pre class="collapse">@article{Moonisa:2022,
  title = {Audio-visual annotation graphs for guiding lens-based scene exploration},
  journal = {Computers & Graphics},
  year = {2022},
  issn = {0097-8493},
  doi = {https://doi.org/10.1016/j.cag.2022.05.003},
  url = { https://dspace.crs4.it/jspui/handle/1138/38},
  author = {Ahsan, Moonisa and Marton, Fabio and Pintus, Ruggero and Gobbetti, Enrico},
  keywords = {Interactive visualization lenses, Annotations, User interfaces, Interactive exploration, Guidance, Guided tour}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1016/j.cag.2022.05.003">https://doi.org/10.1016/j.cag.2022.05.003</a></li>
    
    
      <li><a href=" https://dspace.crs4.it/jspui/handle/1138/38">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1117/12.2618993"><span style="font-variant: small-caps">Guindy, M., Kiran, A.V., Kara, P.A., Balogh, T., and Simon, A.</span> 2022. Towards reconstructing HDR light fields by combining 2D and 3D CNN architectures. <i>Big Data IV: Learning, Analytics, and Applications</i>, SPIE, 192–197.</span>

<div id="10.1117/12.2618993-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1117/12.2618993-bibtex')">BibTeX</a></li>
    <div id="10.1117/12.2618993-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1117/12.2618993,
  author = {Guindy, Mary and Kiran, Adhikarla V. and Kara, Peter A. and Balogh, Tibor and Simon, Aniko},
  title = {{Towards reconstructing HDR light fields by combining 2D and 3D CNN architectures}},
  volume = {12097},
  booktitle = {Big Data IV: Learning, Analytics, and Applications},
  editor = {Ahmad, Fauzia and Markopoulos, Panos P. and Ouyang, Bing},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {192 -- 197},
  keywords = {CNN architecture, light field imaging, light field reconstruction, HDR},
  year = {2022},
  doi = {10.1117/12.2618993},
  url = {https://doi.org/10.1117/12.2618993}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2618993">10.1117/12.2618993</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2618993">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1117/12.2624591"><span style="font-variant: small-caps">Guindy, M., Kara, P.A., Balogh, T., and Simon, A.</span> 2022. Perceptual preference for 3D interactions and realistic physical camera motions on light field displays. <i>Virtual, Augmented, and Mixed Reality (XR) Technology for Multi-Domain Operations III</i>, SPIE, 154–162.</span>

<div id="10.1117/12.2624591-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1117/12.2624591-bibtex')">BibTeX</a></li>
    <div id="10.1117/12.2624591-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1117/12.2624591,
  author = {Guindy, Mary and Kara, Peter A. and Balogh, Tibor and Simon, Aniko},
  title = {{Perceptual preference for 3D interactions and realistic physical camera motions on light field displays}},
  volume = {12125},
  booktitle = {Virtual, Augmented, and Mixed Reality (XR) Technology for Multi-Domain Operations III},
  editor = {Jr., Mark S. Dennison and Krum, David M. and Sanders-Reed, John (Jack) N. and III, Jarvis (Trey) J. Arthur},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {154 -- 162},
  keywords = {light field visualization, realistic camera simulation, physical simulation, 3D interaction, perceptual preference, cinematography},
  year = {2022},
  doi = {10.1117/12.2624591},
  url = {https://doi.org/10.1117/12.2624591}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2624591">10.1117/12.2624591</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2624591">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1117/12.2618979"><span style="font-variant: small-caps">Kara, P.A., Balogh, T., Guindy, M., and Simon, A.</span> 2022. 3D battlespace visualization and defense applications on commercial and use-case-dedicated light field displays. <i>Big Data IV: Learning, Analytics, and Applications</i>, SPIE, 183–191.</span>

<div id="10.1117/12.2618979-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1117/12.2618979-bibtex')">BibTeX</a></li>
    <div id="10.1117/12.2618979-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1117/12.2618979,
  author = {Kara, Peter A. and Balogh, Tibor and Guindy, Mary and Simon, Aniko},
  title = {{3D battlespace visualization and defense applications on commercial and use-case-dedicated light field displays}},
  volume = {12097},
  booktitle = {Big Data IV: Learning, Analytics, and Applications},
  editor = {Ahmad, Fauzia and Markopoulos, Panos P. and Ouyang, Bing},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {183 -- 191},
  keywords = {light field visualization, 3D battlespace, field of view, angular resolution, user interaction, use-case-centric design},
  year = {2022},
  doi = {10.1117/12.2618979},
  url = {https://doi.org/10.1117/12.2618979}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2618979">10.1117/12.2618979</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2618979">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1117/12.2618638"><span style="font-variant: small-caps">Simon, A., Guindy, M., Kara, P.A., Balogh, T., and Szy, L.</span> 2022. Through a different lens: the perceived quality of light field visualization assessed by test participants with imperfect visual acuity and color blindness. <i>Big Data IV: Learning, Analytics, and Applications</i>, SPIE, 212–221.</span>

<div id="10.1117/12.2618638-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1117/12.2618638-bibtex')">BibTeX</a></li>
    <div id="10.1117/12.2618638-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1117/12.2618638,
  author = {Simon, Aniko and Guindy, Mary and Kara, Peter A. and Balogh, Tibor and Szy, Laszlo},
  title = {{Through a different lens: the perceived quality of light field visualization assessed by test participants with imperfect visual acuity and color blindness}},
  volume = {12097},
  booktitle = {Big Data IV: Learning, Analytics, and Applications},
  editor = {Ahmad, Fauzia and Markopoulos, Panos P. and Ouyang, Bing},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {212 -- 221},
  keywords = {light field visualization, visual acuity, color vision, spatial resolution, angular resolution, viewing conditions},
  year = {2022},
  doi = {10.1117/12.2618638},
  url = {https://doi.org/10.1117/12.2618638}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2618638">10.1117/12.2618638</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2618638">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="MANOLAS2022141"><span style="font-variant: small-caps">Manolas, I., Laccone, F., Cherchi, G., Malomo, L., and Cignoni, P.</span> 2022. Automated generation of flat tileable patterns and 3D reduced model simulation. <i>Computers &amp; Graphics</i> <i>106</i>, 141–151.</span>

<div id="MANOLAS2022141-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#MANOLAS2022141-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('MANOLAS2022141-bibtex')">BibTeX</a></li>
    <div id="MANOLAS2022141-bibtex" style="display:none;">
    <pre class="collapse">@article{MANOLAS2022141,
  title = {Automated generation of flat tileable patterns and 3D reduced model simulation},
  journal = {Computers & Graphics},
  volume = {106},
  pages = {141-151},
  year = {2022},
  issn = {0097-8493},
  doi = {https://doi.org/10.1016/j.cag.2022.05.020},
  url = {https://www.sciencedirect.com/science/article/pii/S0097849322000929},
  author = {Manolas, Iason and Laccone, Francesco and Cherchi, Gianmarco and Malomo, Luigi and Cignoni, Paolo},
  keywords = {Computational design, Digital fabrication, Simulation}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1016/j.cag.2022.05.020">https://doi.org/10.1016/j.cag.2022.05.020</a></li>
    
    
      <li><a href="https://www.sciencedirect.com/science/article/pii/S0097849322000929">URL</a></li>
    
  </ul>

  <!--
  <p id="MANOLAS2022141-abstract" class="collapse">The computational fabrication community is developing an increasing interest in the use of patterned surfaces, which can be designed to show ornamental and unconventional aesthetics or to perform as a proper structural material with a wide range of features. Geometrically designing and controlling the deformation capabilities of these patterns in response to external stimuli is a complex task due to the large number of variables involved. This paper introduces a method for generating sets of tileable and exchangeable flat patterns as well as a model-reduction strategy that enables their mechanical simulation at interactive rates. This method is included in a design pipeline that aims to turn any general flat surface into a pattern tessellation, which is able to deform under a given loading scenario. To validate our approach, we apply it to different contexts, including real-scale 3D printed specimens, for which we compare our results with the ones provided by a ground-truth solver.</p>
  -->

</div></li>
<li><span id="10.1145/3522625"><span style="font-variant: small-caps">Cardoso, J.L., Kerbl, B., Yang, L., Uralsky, Y., and Wimmer, M.</span> 2022. Training and Predicting Visual Error for Real-Time Applications. <i>Proc. ACM Comput. Graph. Interact. Tech.</i> <i>5</i>, 1.</span>

<div id="10.1145/3522625-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1145/3522625-bibtex')">BibTeX</a></li>
    <div id="10.1145/3522625-bibtex" style="display:none;">
    <pre class="collapse">@article{10.1145/3522625,
  author = {Cardoso, Joao Liborio and Kerbl, Bernhard and Yang, Lei and Uralsky, Yury and Wimmer, Michael},
  title = {Training and Predicting Visual Error for Real-Time Applications},
  year = {2022},
  issue_date = {May 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {5},
  number = {1},
  url = {https://zenodo.org/record/7107697#.Yy2Vjy8RpB1},
  doi = {10.1145/3522625},
  journal = {Proc. ACM Comput. Graph. Interact. Tech.},
  month = may,
  articleno = {11},
  numpages = {17},
  keywords = {deep learning, perceptual error, variable rate shading, real-time}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1145/3522625">10.1145/3522625</a></li>
    
    
      <li><a href="https://zenodo.org/record/7107697#.Yy2Vjy8RpB1">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1117/12.2619012"><span style="font-variant: small-caps">Simon, A., Szy, L., Kara, P.A., and Guindy, M.</span> 2022. Who watches the watches: on the delivery of the specifications of smart wearable devices and recommendations on the related best practices. <i>Smart Biomedical and Physiological Sensor Technology XIX</i>, SPIE, 1212303.</span>

<div id="10.1117/12.2619012-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1117/12.2619012-bibtex')">BibTeX</a></li>
    <div id="10.1117/12.2619012-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1117/12.2619012,
  author = {Simon, Aniko and Szy, Laszlo and Kara, Peter A. and Guindy, Mary},
  title = {{Who watches the watches: on the delivery of the specifications of smart wearable devices and recommendations on the related best practices}},
  volume = {12123},
  booktitle = {Smart Biomedical and Physiological Sensor Technology XIX},
  editor = {Cullum, Brian M. and Kiehl, Douglas and McLamore, Eric S.},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {1212303},
  keywords = {smart wearables, wearable devices, wearable sensor technologies, assistive wearable technologies, device specification},
  year = {2022},
  doi = {10.1117/12.2619012},
  url = {https://doi.org/10.1117/12.2619012}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2619012">10.1117/12.2619012</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2619012">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1117/12.2625118"><span style="font-variant: small-caps">Geyer, F.A., Szakal, V.A., Kara, P.A., Simon, A., and Guindy, M.</span> 2022. Thresholds of perceptual fatigue based on 3D object motion vectors and relative object size in virtual reality. <i>Virtual, Augmented, and Mixed Reality (XR) Technology for Multi-Domain Operations III</i>, SPIE, 121250I.</span>

<div id="10.1117/12.2625118-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1117/12.2625118-bibtex')">BibTeX</a></li>
    <div id="10.1117/12.2625118-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1117/12.2625118,
  author = {Geyer, Fanni A. and Szakal, Vince A. and Kara, Peter A. and Simon, Aniko and Guindy, Mary},
  title = {{Thresholds of perceptual fatigue based on 3D object motion vectors and relative object size in virtual reality}},
  volume = {12125},
  booktitle = {Virtual, Augmented, and Mixed Reality (XR) Technology for Multi-Domain Operations III},
  editor = {Jr., Mark S. Dennison and Krum, David M. and Sanders-Reed, John (Jack) N. and III, Jarvis (Trey) J. Arthur},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {121250I},
  keywords = {virtual reality, perceptual fatigue, human factors, operation time, 3D object motion vector, relative object size},
  year = {2022},
  doi = {10.1117/12.2625118},
  url = {https://doi.org/10.1117/12.2625118}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2625118">10.1117/12.2625118</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2625118">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="electronics11172689"><span style="font-variant: small-caps">Guindy, M., Barsi, A., Kara, P.A., Adhikarla, V.K., Balogh, T., and Simon, A.</span> 2022. Camera Animation for Immersive Light Field Imaging. <i>Electronics</i> <i>11</i>, 17.</span>

<div id="electronics11172689-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('electronics11172689-bibtex')">BibTeX</a></li>
    <div id="electronics11172689-bibtex" style="display:none;">
    <pre class="collapse">@article{electronics11172689,
  author = {Guindy, Mary and Barsi, Attila and Kara, Peter A. and Adhikarla, Vamsi K. and Balogh, Tibor and Simon, Aniko},
  title = {Camera Animation for Immersive Light Field Imaging},
  journal = {Electronics},
  volume = {11},
  year = {2022},
  number = {17},
  article-number = {2689},
  url = {https://www.mdpi.com/2079-9292/11/17/2689},
  issn = {2079-9292},
  doi = {10.3390/electronics11172689}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.3390/electronics11172689">10.3390/electronics11172689</a></li>
    
    
      <li><a href="https://www.mdpi.com/2079-9292/11/17/2689">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Tarek:2023"><span style="font-variant: small-caps">Haila, T.A., Tausch, R., Ritz, M., Santos, P., and Fellner, D.</span> 2022. Effect of Polarization on RGB Imaging and Color Accuracy/Fidelity. <i>Color and Imaging Conference</i>, Society for Imaging Science and Technology.</span>

<div id="Tarek:2023-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Tarek:2023-bibtex')">BibTeX</a></li>
    <div id="Tarek:2023-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Tarek:2023,
  booktitle = {Color and Imaging Conference},
  title = {Effect of Polarization on RGB Imaging and Color Accuracy/Fidelity},
  author = {Haila, Tarek Abu and Tausch, Reimar and Ritz, Martin and Santos, Pedro and Fellner, Dieter},
  year = {2022},
  publisher = {Society for Imaging Science and Technology},
  doi = {https://doi.org/10.2352/CIC.2022.30.1.30},
  url = {https://doi.org/10.2352/CIC.2022.30.1.30}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.2352/CIC.2022.30.1.30">https://doi.org/10.2352/CIC.2022.30.1.30</a></li>
    
    
      <li><a href="https://doi.org/10.2352/CIC.2022.30.1.30">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="isprs-archives-XLIII-B1-2022-121-2022"><span style="font-variant: small-caps">Sgrenzaroli, M., Ortiz Barrientos, J., Vassena, G., et al.</span> 2022. INDOOR MOBILE MAPPING SYSTEMS AND (BIM) DIGITAL MODELS FOR CONSTRUCTION PROGRESS MONITORING. <i>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</i> <i>XLIII-B1-2022</i>, 121–127.</span>

<div id="isprs-archives-XLIII-B1-2022-121-2022-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('isprs-archives-XLIII-B1-2022-121-2022-bibtex')">BibTeX</a></li>
    <div id="isprs-archives-XLIII-B1-2022-121-2022-bibtex" style="display:none;">
    <pre class="collapse">@article{isprs-archives-XLIII-B1-2022-121-2022,
  author = {Sgrenzaroli, M. and Ortiz Barrientos, J. and Vassena, G. and Sanchez, A. and Ciribini, A. and Mastrolembo Ventura, S. and Comai, S.},
  title = {INDOOR MOBILE MAPPING SYSTEMS AND (BIM) DIGITAL MODELS FOR CONSTRUCTION PROGRESS MONITORING},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume = {XLIII-B1-2022},
  year = {2022},
  pages = {121--127},
  url = {https://isprs-archives.copernicus.org/articles/XLIII-B1-2022/121/2022/},
  doi = {10.5194/isprs-archives-XLIII-B1-2022-121-2022}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.5194/isprs-archives-XLIII-B1-2022-121-2022">10.5194/isprs-archives-XLIII-B1-2022-121-2022</a></li>
    
    
      <li><a href="https://isprs-archives.copernicus.org/articles/XLIII-B1-2022/121/2022/">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="LMMC22"><span style="font-variant: small-caps">Laccone, F., Manolas, I., Malomo, L., and Cignoni, P.</span> 2022. Exploratory study on a segmented shell made of recycled-HDPE plastic. <i>Inspiring the Next Generation, p.3590; International Conference on Spatial Structures 2020/21, 7</i>, Spatial Structures Research Centre of the University of Surrey.</span>

<div id="LMMC22-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('LMMC22-bibtex')">BibTeX</a></li>
    <div id="LMMC22-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{LMMC22,
  author = {Laccone, Francesco and Manolas, Iason and Malomo, Luigi and Cignoni, Paolo},
  title = {Exploratory study on a segmented shell made of recycled-HDPE plastic},
  booktitle = {Inspiring the Next Generation, p.3590; International Conference on Spatial Structures 2020/21, 7},
  year = {2022},
  editor = {SEYED ALIREZA BEHNEJAD, GAR Parke, OMIDALI SAMAVATI},
  publisher = {Spatial Structures Research Centre of the University of Surrey},
  keywords = {conceptual design, construction systems, segmented shell, recycled polyethylene, structural design, dry-assembly, bending, non-funicular},
  url = {http://vcg.isti.cnr.it/Publications/2022/LMMC22}
}
</pre>
    </div>-->

    
    
    
      <li><a href="http://vcg.isti.cnr.it/Publications/2022/LMMC22">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="oai:it.cnr:prodotti:473398"><span style="font-variant: small-caps">I., M., F., L., G., C., L., M., and P., C.</span> 2022. A computational tool for the analysis of 3D bending-active structures based on the dynamic relaxation method. <i>Smart Tools and Applications in Graphics - Eurographics Italian Chapter Conference, Cagliari, Italy, 17-18/11/2022</i>, Eurographics Association, Eindhoven, NLD.</span>

<div id="oai:it.cnr:prodotti:473398-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('oai:it.cnr:prodotti:473398-bibtex')">BibTeX</a></li>
    <div id="oai:it.cnr:prodotti:473398-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{oai:it.cnr:prodotti:473398,
  title = {A computational tool for the analysis of 3D bending-active structures based on the dynamic relaxation method},
  author = {I., Manolas and F., Laccone and G., Cherchi and L., Malomo and P., Cignoni},
  publisher = {Eurographics Association, Eindhoven, NLD},
  doi = {10.2312/stag.20221250},
  booktitle = {Smart Tools and Applications in Graphics - Eurographics Italian Chapter Conference, Cagliari, Italy, 17-18/11/2022},
  year = {2022},
  url = {https://openportal.isti.cnr.it/doc?id=people______::1c90814c2536f51ed873823f98d6778d}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.2312/stag.20221250">10.2312/stag.20221250</a></li>
    
    
      <li><a href="https://openportal.isti.cnr.it/doc?id=people______::1c90814c2536f51ed873823f98d6778d">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Mary:2022"><span style="font-variant: small-caps">Kara, P.A., Tamboli, R.R., Shafiee, E., Martini, M.G., Simon, A., and Guindy, M.</span> 2022. Beyond Perceptual Thresholds and Personal Preference: Towards Novel Research Questions and Methodologies of Quality of Experience Studies on Light Field Visualization. <i>Electronics</i> <i>11</i>, 6, 953.</span>

<div id="Mary:2022-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Mary:2022-bibtex')">BibTeX</a></li>
    <div id="Mary:2022-bibtex" style="display:none;">
    <pre class="collapse">@article{Mary:2022,
  title = {Beyond Perceptual Thresholds and Personal Preference: Towards Novel Research Questions and Methodologies of Quality of Experience Studies on Light Field Visualization},
  volume = {11},
  issn = {2079-9292},
  url = {http://dx.doi.org/10.3390/electronics11060953},
  doi = {10.3390/electronics11060953},
  number = {6},
  journal = {Electronics},
  publisher = {MDPI AG},
  author = {Kara, Peter A. and Tamboli, Roopak R. and Shafiee, Edris and Martini, Maria G. and Simon, Aniko and Guindy, Mary},
  year = {2022},
  month = mar,
  pages = {953}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.3390/electronics11060953">10.3390/electronics11060953</a></li>
    
    
      <li><a href="http://dx.doi.org/10.3390/electronics11060953">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1117/12.2633912"><span style="font-variant: small-caps">Guindy, M., Kara, P.A., Balogh, T., and Simon, A.</span> 2022. Analysis of high dynamic range light field images in practical utilization contexts. <i>Novel Optical Systems, Methods, and Applications XXV</i>, SPIE, 122160P.</span>

<div id="10.1117/12.2633912-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1117/12.2633912-bibtex')">BibTeX</a></li>
    <div id="10.1117/12.2633912-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1117/12.2633912,
  author = {Guindy, Mary and Kara, Peter A. and Balogh, Tibor and Simon, Aniko},
  title = {{Analysis of high dynamic range light field images in practical utilization contexts}},
  volume = {12216},
  booktitle = {Novel Optical Systems, Methods, and Applications XXV},
  editor = {Hahlweg, Cornelius F. and Mulley, Joseph R.},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {122160P},
  keywords = {light field, high dynamic range, mage reconstruction, usage-specific requirements},
  year = {2022},
  doi = {10.1117/12.2633912},
  url = {https://doi.org/10.1117/12.2633912}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2633912">10.1117/12.2633912</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2633912">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.1117/12.2633613"><span style="font-variant: small-caps">Simon, A., Kara, P.A., Guindy, M., Qiu, X., Szy, L., and Balogh, T.</span> 2022. One step closer to a better experience: analysis of the suitable viewing distance ranges of light field visualization usage contexts for observers with reduced visual capabilities. <i>Novel Optical Systems, Methods, and Applications XXV</i>, SPIE, 122160O.</span>

<div id="10.1117/12.2633613-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1117/12.2633613-bibtex')">BibTeX</a></li>
    <div id="10.1117/12.2633613-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1117/12.2633613,
  author = {Simon, Aniko and Kara, Peter A. and Guindy, Mary and Qiu, Xinyu and Szy, Laszlo and Balogh, Tibor},
  title = {{One step closer to a better experience: analysis of the suitable viewing distance ranges of light field visualization usage contexts for observers with reduced visual capabilities}},
  volume = {12216},
  booktitle = {Novel Optical Systems, Methods, and Applications XXV},
  editor = {Hahlweg, Cornelius F. and Mulley, Joseph R.},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {122160O},
  keywords = {light field visualization, viewing distance, human visual system, use-case-specific preference},
  year = {2022},
  doi = {10.1117/12.2633613},
  url = {https://doi.org/10.1117/12.2633613}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2633613">10.1117/12.2633613</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2633613">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Mary/12.2633613"><span style="font-variant: small-caps">Guindy, M., Adhikarla, V.K., Kara, P.A., Balogh, T., and Simon, A.</span> 2022. CLASSROOM : synthetic high dynamic range light field dataset. <i>Applications of Digital Image Processing XLV</i>, SPIE, 22–24.</span>

<div id="Mary/12.2633613-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Mary/12.2633613-bibtex')">BibTeX</a></li>
    <div id="Mary/12.2633613-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Mary/12.2633613,
  author = {Guindy, Mary and Adhikarla, Vamsi K. and Kara, Peter Andras and Balogh, Tibor and Simon, Aniko},
  title = {{CLASSROOM : synthetic high dynamic range light field dataset}},
  booktitle = {Applications of Digital Image Processing XLV},
  publisher = {SPIE},
  pages = {22--24},
  year = {2022},
  url = {https://eprints.kingston.ac.uk/id/eprint/52218}
}
</pre>
    </div>-->

    
    
    
      <li><a href="https://eprints.kingston.ac.uk/id/eprint/52218">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Siddique:stag.20211489"><span style="font-variant: small-caps">Siddique, A., Corsini, M., Ganovelli, F., and Cignoni, P.</span> 2021. Evaluating Deep Learning Methods for Low Resolution Point Cloud Registration in Outdoor Scenarios. <i>Smart Tools and Apps for Graphics - Eurographics Italian Chapter Conference</i>, The Eurographics Association.</span>

<div id="Siddique:stag.20211489-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Siddique:stag.20211489-bibtex')">BibTeX</a></li>
    <div id="Siddique:stag.20211489-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Siddique:stag.20211489,
  booktitle = {Smart Tools and Apps for Graphics - Eurographics Italian Chapter Conference},
  editor = {Frosini, Patrizio and Giorgi, Daniela and Melzi, Simone and Rodola, Emanuele},
  title = {{Evaluating Deep Learning Methods for Low Resolution Point Cloud Registration in Outdoor Scenarios}},
  author = {Siddique, Arslan and Corsini, Massimiliano and Ganovelli, Fabio and Cignoni, Paolo},
  year = {2021},
  publisher = {The Eurographics Association},
  issn = {2617-4855},
  isbn = {978-3-03868-165-6},
  doi = {10.2312/stag.20211489},
  url = {https://openportal.isti.cnr.it/doc?id=people______::ef8db891a81ad9a13f030f3e4dc2e14c}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.2312/stag.20211489">10.2312/stag.20211489</a></li>
    
    
      <li><a href="https://openportal.isti.cnr.it/doc?id=people______::ef8db891a81ad9a13f030f3e4dc2e14c">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Balogh:2021_7"><span style="font-variant: small-caps">Balogh, T., Barsi, A., Kara, P.A., Guindy, M., Simon, A., and Nagy, Z.</span> 2021. 3D light field LED wall. <i>Digital Optical Technologies 2021</i>, SPIE, 180–190.</span>

<div id="Balogh:2021_7-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Balogh:2021_7-bibtex')">BibTeX</a></li>
    <div id="Balogh:2021_7-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Balogh:2021_7,
  author = {Balogh, Tibor and Barsi, Attila and Kara, Peter A. and Guindy, Mary and Simon, Aniko and Nagy, Zsolt},
  title = {{3D light field LED wall}},
  volume = {11788},
  booktitle = {Digital Optical Technologies 2021},
  editor = {Kress, Bernard C. and Peroz, Christophe},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {180 -- 190},
  keywords = {3D light field, novel system design, LED, lens array, modular display},
  year = {2021},
  doi = {https://doi.org/10.1117/12.2594276},
  url = {https://doi.org/10.1117/12.2594276}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1117/12.2594276">https://doi.org/10.1117/12.2594276</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2594276">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Peter:2021_8"><span style="font-variant: small-caps">Kara, P.A., Barsi, A., Tamboli, R.R., et al.</span> 2021. Recommendations on the viewing distance of light field displays. <i>Digital Optical Technologies 2021</i>, SPIE, 166–179.</span>

<div id="Peter:2021_8-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Peter:2021_8-bibtex')">BibTeX</a></li>
    <div id="Peter:2021_8-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Peter:2021_8,
  author = {Kara, Peter A. and Barsi, Attila and Tamboli, Roopak R. and Guindy, Mary and Martini, Maria G. and Balogh, Tibor and Simon, Aniko},
  title = {{Recommendations on the viewing distance of light field displays}},
  volume = {11788},
  booktitle = {Digital Optical Technologies 2021},
  editor = {Kress, Bernard C. and Peroz, Christophe},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {166 -- 179},
  keywords = {light field, 3D perception, viewing conditions, key performance indicators, user-centric design},
  year = {2021},
  doi = {https://doi.org/10.1117/12.2594266},
  url = {https://doi.org/10.1117/12.2594266}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1117/12.2594266">https://doi.org/10.1117/12.2594266</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2594266">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Pintore:2021_CVPR"><span style="font-variant: small-caps">Pintore, G., Agus, M., Almansa, E., Schneider, J., and Gobbetti, E.</span> 2021. SliceNet: Deep Dense Depth Estimation From a Single Indoor Panorama Using a Slice-Based Representation. <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 11536–11545.</span>

<div id="Pintore:2021_CVPR-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Pintore:2021_CVPR-bibtex')">BibTeX</a></li>
    <div id="Pintore:2021_CVPR-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Pintore:2021_CVPR,
  author = {Pintore, Giovanni and Agus, Marco and Almansa, Eva and Schneider, Jens and Gobbetti, Enrico},
  title = {SliceNet: Deep Dense Depth Estimation From a Single Indoor Panorama Using a Slice-Based Representation},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = jun,
  year = {2021},
  pages = {11536-11545},
  url = {https://dspace.crs4.it/jspui/handle/1138/32}
}
</pre>
    </div>-->

    
    
    
      <li><a href="https://dspace.crs4.it/jspui/handle/1138/32">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Pintore:2021:GAR"><span style="font-variant: small-caps">Pintore, G., Almansa, E., Agus, M., and Gobbetti, E.</span> 2021. Deep3DLayout: 3D Reconstruction of an Indoor Layout from a Spherical Panoramic Image. <i>ACM Transactions on Graphics</i> <i>40</i>, 6, 250:1–250:12.</span>

<div id="Pintore:2021:GAR-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Pintore:2021:GAR-bibtex')">BibTeX</a></li>
    <div id="Pintore:2021:GAR-bibtex" style="display:none;">
    <pre class="collapse">@article{Pintore:2021:GAR,
  author = {Pintore, Giovanni and Almansa, Eva and Agus, Marco and Gobbetti, Enrico},
  title = {{Deep3DLayout}: {3D} Reconstruction of an Indoor Layout from a Spherical Panoramic Image},
  journal = {ACM Transactions on Graphics},
  volume = {40},
  number = {6},
  pages = {250:1--250:12},
  month = dec,
  year = {2021},
  doi = {10.1145/3478513.3480480},
  note = {Proc. SIGGRAPH Asia 2021. To appear},
  url = {http://vic.crs4.it/vic/cgi-bin/bib-page.cgi?id='Pintore:2021:GAR'}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1145/3478513.3480480">10.1145/3478513.3480480</a></li>
    
    
      <li><a href="http://vic.crs4.it/vic/cgi-bin/bib-page.cgi?id=’Pintore:2021:GAR’">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="10.2312:stag.20211477"><span style="font-variant: small-caps">Ahsan, M., Marton, F., Pintus, R., and Gobbetti, E.</span> 2021. Guiding Lens-based Exploration using Annotation Graphs. <i>Smart Tools and Apps for Graphics - Eurographics Italian Chapter Conference</i>, The Eurographics Association.</span>

<div id="10.2312:stag.20211477-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.2312:stag.20211477-bibtex')">BibTeX</a></li>
    <div id="10.2312:stag.20211477-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.2312:stag.20211477,
  booktitle = {Smart Tools and Apps for Graphics - Eurographics Italian Chapter Conference},
  editor = {Frosini, Patrizio and Giorgi, Daniela and Melzi, Simone and Rodola, Emanuele},
  title = {{Guiding Lens-based Exploration using Annotation Graphs}},
  author = {Ahsan, Moonisa and Marton, Fabio and Pintus, Ruggero and Gobbetti, Enrico},
  year = {2021},
  publisher = {The Eurographics Association},
  issn = {2617-4855},
  isbn = {978-3-03868-165-6},
  doi = {10.2312/stag.20211477},
  url = {https://dspace.crs4.it/jspui/handle/1138/35 }
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.2312/stag.20211477">10.2312/stag.20211477</a></li>
    
    
      <li><a href="https://dspace.crs4.it/jspui/handle/1138/35 ">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="MOHANTO2021"><span style="font-variant: small-caps">Mohanto, B., Islam, A.B.M.T., Gobbetti, E., and Staadt, O.</span> 2021. An integrative view of foveated rendering. <i>Computers &amp; Graphics</i>.</span>

<div id="MOHANTO2021-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#MOHANTO2021-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('MOHANTO2021-bibtex')">BibTeX</a></li>
    <div id="MOHANTO2021-bibtex" style="display:none;">
    <pre class="collapse">@article{MOHANTO2021,
  title = {An integrative view of foveated rendering},
  journal = {Computers & Graphics},
  year = {2021},
  issn = {0097-8493},
  doi = {https://doi.org/10.1016/j.cag.2021.10.010},
  url = {https://www.sciencedirect.com/science/article/pii/S0097849321002211},
  author = {Mohanto, Bipul and Islam, ABM Tariqul and Gobbetti, Enrico and Staadt, Oliver},
  keywords = {Foveated rendering, Gaze-contingent rendering, Adaptive resolution, Geometric simplification, Shading simplification, Chromatic degradation, Spatio-temporal deterioration}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1016/j.cag.2021.10.010">https://doi.org/10.1016/j.cag.2021.10.010</a></li>
    
    
      <li><a href="https://www.sciencedirect.com/science/article/pii/S0097849321002211">URL</a></li>
    
  </ul>

  <!--
  <p id="MOHANTO2021-abstract" class="collapse">Foveated rendering adapts the image synthesis process to the user’s gaze. By exploiting the human visual system’s limitations, in particular in terms of reduced acuity in peripheral vision, it strives to deliver high-quality visual experiences at very reduced computational, storage, and transmission costs. Despite the very substantial progress made in the past decades, the solution landscape is still fragmented, and several research problems remain open. In this work, we present an up-to-date integrative view of the domain from the point of view of the rendering methods employed, discussing general characteristics, commonalities, differences, advantages, and limitations. We cover, in particular, techniques based on adaptive resolution, geometric simplification, shading simplification, chromatic degradation, as well spatio-temporal deterioration. Next, we review the main areas where foveated rendering is already in use today. We finally point out relevant research issues and analyze research trends.</p>
  -->

</div></li>
<li><span id="10.2312:gch.20211412"><span style="font-variant: small-caps">Pintus, R., Ahsan, M., Marton, F., and Gobbetti, E.</span> 2021. Exploiting Neighboring Pixels Similarity for Effective SV-BRDF Reconstruction from Sparse MLICs. <i>Eurographics Workshop on Graphics and Cultural Heritage</i>, The Eurographics Association.</span>

<div id="10.2312:gch.20211412-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.2312:gch.20211412-bibtex')">BibTeX</a></li>
    <div id="10.2312:gch.20211412-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.2312:gch.20211412,
  booktitle = {Eurographics Workshop on Graphics and Cultural Heritage},
  editor = {Hulusic, Vedad and Chalmers, Alan},
  title = {{Exploiting Neighboring Pixels Similarity for Effective SV-BRDF Reconstruction from Sparse MLICs}},
  author = {Pintus, Ruggero and Ahsan, Moonisa and Marton, Fabio and Gobbetti, Enrico},
  year = {2021},
  publisher = {The Eurographics Association},
  issn = {2312-6124},
  isbn = {978-3-03868-141-0},
  doi = {10.2312/gch.20211412},
  url = {https://dspace.crs4.it/jspui/handle/1138/36 }
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.2312/gch.20211412">10.2312/gch.20211412</a></li>
    
    
      <li><a href="https://dspace.crs4.it/jspui/handle/1138/36 ">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Guindy:2021_7"><span style="font-variant: small-caps">Kara, P.A., Guindy, M., Balogh, T., and Simon, A.</span> 2021. The Perceptually-Supported and the Subjectively-Preferred Viewing Distance of Projection-Based Light Field Displays. <i>2021 International Conference on 3D Immersion (IC3D)</i>, 1–8.</span>

<div id="Guindy:2021_7-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Guindy:2021_7-bibtex')">BibTeX</a></li>
    <div id="Guindy:2021_7-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Guindy:2021_7,
  author = {Kara, Peter A. and Guindy, Mary and Balogh, Tibor and Simon, Aniko},
  booktitle = {2021 International Conference on 3D Immersion (IC3D)},
  title = {The Perceptually-Supported and the Subjectively-Preferred Viewing Distance of Projection-Based Light Field Displays},
  year = {2021},
  volume = {},
  number = {},
  pages = {1-8},
  doi = {10.1109/IC3D53758.2021.9687222},
  url = {https://eprints.kingston.ac.uk/id/eprint/50847/}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1109/IC3D53758.2021.9687222">10.1109/IC3D53758.2021.9687222</a></li>
    
    
      <li><a href="https://eprints.kingston.ac.uk/id/eprint/50847/">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="9687182"><span style="font-variant: small-caps">Guindy, M., Kiran, A.V., Kara, P.A., Balogh, T., and Simon, A.</span> 2021. Performance Evaluation of HDR Image Reconstruction Techniques on Light Field Images. <i>2021 International Conference on 3D Immersion (IC3D)</i>, 1–7.</span>

<div id="9687182-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('9687182-bibtex')">BibTeX</a></li>
    <div id="9687182-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{9687182,
  author = {Guindy, Mary and Kiran, Adhikarla V. and Kara, Peter A. and Balogh, Tibor and Simon, Aniko},
  booktitle = {2021 International Conference on 3D Immersion (IC3D)},
  title = {Performance Evaluation of HDR Image Reconstruction Techniques on Light Field Images},
  year = {2021},
  volume = {},
  number = {},
  pages = {1-7},
  doi = {10.1109/IC3D53758.2021.9687182},
  url = {https://eprints.kingston.ac.uk/id/eprint/50849/}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1109/IC3D53758.2021.9687182">10.1109/IC3D53758.2021.9687182</a></li>
    
    
      <li><a href="https://eprints.kingston.ac.uk/id/eprint/50849/">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="9687271"><span style="font-variant: small-caps">Appina, B., Sharma, M., Kumar, S., Kara, P.A., Simon, A., and Guindy, M.</span> 2021. Latent Factor Modeling of Perceived Quality for Stereoscopic 3D Video Recommendation. <i>2021 International Conference on 3D Immersion (IC3D)</i>, 1–8.</span>

<div id="9687271-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('9687271-bibtex')">BibTeX</a></li>
    <div id="9687271-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{9687271,
  author = {Appina, Balasubramanyam and Sharma, Mansi and Kumar, Santosh and Kara, Peter A. and Simon, Aniko and Guindy, Mary},
  booktitle = {2021 International Conference on 3D Immersion (IC3D)},
  title = {Latent Factor Modeling of Perceived Quality for Stereoscopic 3D Video Recommendation},
  year = {2021},
  volume = {},
  number = {},
  pages = {1-8},
  doi = {10.1109/IC3D53758.2021.9687271},
  url = {https://eprints.kingston.ac.uk/id/eprint/50848/}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1109/IC3D53758.2021.9687271">10.1109/IC3D53758.2021.9687271</a></li>
    
    
      <li><a href="https://eprints.kingston.ac.uk/id/eprint/50848/">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="https://doi.org/10.1111/cgf.142640"><span style="font-variant: small-caps">Mura, C., Pajarola, R., Schindler, K., and Mitra, N.</span> 2021. Walk2Map: Extracting Floor Plans from Indoor Walk Trajectories. <i>Computer Graphics Forum</i> <i>40</i>, 2, 375–388.</span>

<div id="https://doi.org/10.1111/cgf.142640-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#https://doi.org/10.1111/cgf.142640-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('https://doi.org/10.1111/cgf.142640-bibtex')">BibTeX</a></li>
    <div id="https://doi.org/10.1111/cgf.142640-bibtex" style="display:none;">
    <pre class="collapse">@article{https://doi.org/10.1111/cgf.142640,
  author = {Mura, Claudio and Pajarola, Renato and Schindler, Konrad and Mitra, Niloy},
  title = {Walk2Map: Extracting Floor Plans from Indoor Walk Trajectories},
  journal = {Computer Graphics Forum},
  volume = {40},
  number = {2},
  pages = {375-388},
  keywords = {CCS Concepts, • Computing methodologies → Reconstruction; Object detection; Scene understanding; Machine learning},
  doi = {https://doi.org/10.1111/cgf.142640},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.142640},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.142640},
  year = {2021}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1111/cgf.142640">https://doi.org/10.1111/cgf.142640</a></li>
    
    
      <li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.142640">URL</a></li>
    
  </ul>

  <!--
  <p id="https://doi.org/10.1111/cgf.142640-abstract" class="collapse">Abstract Recent years have seen a proliferation of new digital products for the efficient management of indoor spaces, with important applications like emergency management, virtual property showcasing and interior design. While highly innovative and effective, these products rely on accurate 3D models of the environments considered, including information on both architectural and non-permanent elements. These models must be created from measured data such as RGB-D images or 3D point clouds, whose capture and consolidation involves lengthy data workflows. This strongly limits the rate at which 3D models can be produced, preventing the adoption of many digital services for indoor space management. We provide a radical alternative to such data-intensive procedures by presenting Walk2Map, a data-driven approach to generate floor plans only from trajectories of a person walking inside the rooms. Thanks to recent advances in data-driven inertial odometry, such minimalistic input data can be acquired from the IMU readings of consumer-level smartphones, which allows for an effortless and scalable mapping of real-world indoor spaces. Our work is based on learning the latent relation between an indoor walk trajectory and the information represented in a floor plan: interior space footprint, portals, and furniture. We distinguish between recovering area-related (interior footprint, furniture) and wall-related (doors) information and use two different neural architectures for the two tasks: an image-based Encoder-Decoder and a Graph Convolutional Network, respectively. We train our networks using scanned 3D indoor models and apply them in a cascaded fashion on an indoor walk trajectory at inference time. We perform a qualitative and quantitative evaluation using both trajectories simulated from scanned models of interiors and measured, real-world trajectories, and compare against a baseline method for image-to-image translation. The experiments confirm that our technique is viable and allows recovering reliable floor plans from minimal walk trajectory data.</p>
  -->

</div></li>
<li><span id="chen29deep"><span style="font-variant: small-caps">Chen, D. and Urban, P.</span> 2021. Deep learning models for optically characterizing 3D printers. <i>Optics Express</i> <i>29</i>, 2, 615–631.</span>

<div id="chen29deep-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('chen29deep-bibtex')">BibTeX</a></li>
    <div id="chen29deep-bibtex" style="display:none;">
    <pre class="collapse">@article{chen29deep,
  title = {Deep learning models for optically characterizing 3D printers},
  author = {Chen, Danwu and Urban, Philipp},
  journal = {Optics Express},
  volume = {29},
  month = jan,
  number = {2},
  pages = {615--631},
  url = {http://publica.fraunhofer.de/documents/N-621396.html},
  doi = {10.1364/OE.410796},
  publisher = {Optical Society of America},
  year = {2021}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1364/OE.410796">10.1364/OE.410796</a></li>
    
    
      <li><a href="http://publica.fraunhofer.de/documents/N-621396.html">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Ahsan:2021"><span style="font-variant: small-caps">Jaspe-Villanueva, A., Ahsan, M., Pintus, R., Giachetti, A., Marton, F., and Gobbetti, E.</span> 2021. Web-Based Exploration of Annotated Multi-Layered Relightable Image Models. <i>Journal on Computing and Cultural Heritage</i> <i>14</i>, 2.</span>

<div id="Ahsan:2021-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Ahsan:2021-bibtex')">BibTeX</a></li>
    <div id="Ahsan:2021-bibtex" style="display:none;">
    <pre class="collapse">@article{Ahsan:2021,
  author = {Jaspe-Villanueva, Alberto and Ahsan, Moonisa and Pintus, Ruggero and Giachetti, Andrea and Marton, Fabio and Gobbetti, Enrico},
  title = {Web-Based Exploration of Annotated Multi-Layered Relightable Image Models},
  month = may,
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {14},
  number = {2},
  issn = {1556-4673},
  url = {https://doi.org/10.1145/3430846},
  doi = {10.1145/3430846},
  journal = {Journal on Computing and Cultural Heritage},
  articleno = {24},
  numpages = {29},
  year = {2021}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1145/3430846">10.1145/3430846</a></li>
    
    
      <li><a href="https://doi.org/10.1145/3430846">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Mary:2021_1"><span style="font-variant: small-caps">Guindy, M., Barsi, A., Kara, P.A., Balogh, T., and Simon, A.</span> 2021. Interaction methods for light field displays by means of a theater model environment. <i>Holography: Advances and Modern Trends VII</i>, SPIE, 109–118.</span>

<div id="Mary:2021_1-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Mary:2021_1-bibtex')">BibTeX</a></li>
    <div id="Mary:2021_1-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Mary:2021_1,
  author = {Guindy, Mary and Barsi, Attila and Kara, Peter A. and Balogh, Tibor and Simon, Aniko},
  title = {{Interaction methods for light field displays by means of a theater model environment}},
  volume = {11774},
  booktitle = {Holography: Advances and Modern Trends VII},
  editor = {Fimia, Antonio and Hrabovský, Miroslav and Sheridan, John T.},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {109 -- 118},
  keywords = {Light field, User interface, 3D rendering, Light field visualization},
  year = {2021},
  month = apr,
  doi = {10.1117/12.2589126},
  url = {https://doi.org/10.1117/12.2589126}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2589126">10.1117/12.2589126</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2589126">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Mary:2021_2"><span style="font-variant: small-caps">Guindy, M., Barsi, A., Kara, P.A., Balogh, T., and Simon, A.</span> 2021. Realistic physical camera motion for light field visualization. <i>Holography: Advances and Modern Trends VII</i>, SPIE, 70–77.</span>

<div id="Mary:2021_2-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Mary:2021_2-bibtex')">BibTeX</a></li>
    <div id="Mary:2021_2-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Mary:2021_2,
  author = {Guindy, Mary and Barsi, Attila and Kara, Peter A. and Balogh, Tibor and Simon, Aniko},
  title = {{Realistic physical camera motion for light field visualization}},
  volume = {11774},
  booktitle = {Holography: Advances and Modern Trends VII},
  editor = {Fimia, Antonio and Hrabovský, Miroslav and Sheridan, John T.},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {70 -- 77},
  keywords = {Light field, Virtual cameras,  Physical camera simulation, Camera motion, Cinematography},
  year = {2021},
  month = apr,
  doi = {10.1117/12.2589128},
  url = {https://doi.org/10.1117/12.2589128}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2589128">10.1117/12.2589128</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2589128">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Mary:2021_3"><span style="font-variant: small-caps">Guindy, M., Barsi, A., Kara, P.A., Balogh, T., and Simon, A.</span> 2021. On the simulation of hand-held cameras in light-field rendering. <i>Holography: Advances and Modern Trends VII</i>, SPIE, 119–124.</span>

<div id="Mary:2021_3-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Mary:2021_3-bibtex')">BibTeX</a></li>
    <div id="Mary:2021_3-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Mary:2021_3,
  author = {Guindy, Mary and Barsi, Attila and Kara, Peter A. and Balogh, Tibor and Simon, Aniko},
  title = {{On the simulation of hand-held cameras in light-field rendering}},
  volume = {11774},
  booktitle = {Holography: Advances and Modern Trends VII},
  editor = {Fimia, Antonio and Hrabovský, Miroslav and Sheridan, John T.},
  organization = {International Society for Optics and Photonics},
  publisher = {SPIE},
  pages = {119 -- 124},
  keywords = {Light field, Hand-held cameras, Camera motion, Camera motion path, 3D rendering},
  year = {2021},
  month = apr,
  doi = {10.1117/12.2589129},
  url = {https://doi.org/10.1117/12.2589129}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1117/12.2589129">10.1117/12.2589129</a></li>
    
    
      <li><a href="https://doi.org/10.1117/12.2589129">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Cardoso:2021_4"><span style="font-variant: small-caps">Cardoso, J.A., Goncalves, N., and Wimmer, M.</span> 2021. Cost Volume Refinement for Depth Prediction. <i>2020 25th International Conference on Pattern Recognition (ICPR)</i>, 354–361.</span>

<div id="Cardoso:2021_4-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Cardoso:2021_4-bibtex')">BibTeX</a></li>
    <div id="Cardoso:2021_4-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{Cardoso:2021_4,
  author = {Cardoso, Joao Afonso and Goncalves, Nuno and Wimmer, Michael},
  booktitle = {2020 25th International Conference on Pattern Recognition (ICPR)},
  title = {Cost Volume Refinement for Depth Prediction},
  year = {2021},
  month = jan,
  pages = {354 -- 361},
  doi = {10.1109/ICPR48806.2021.9412730},
  url = {https://doi.org/10.1109/ICPR48806.2021.9412730}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1109/ICPR48806.2021.9412730">10.1109/ICPR48806.2021.9412730</a></li>
    
    
      <li><a href="https://doi.org/10.1109/ICPR48806.2021.9412730">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Bettio:2021_6"><span style="font-variant: small-caps">Bettio, F., Ahsan, M., Marton, F., and Gobbetti, E.</span> 2021. A Novel Approach for Exploring Annotated Data With Interactive Lenses. <i>Computer Graphics Forum</i>.</span>

<div id="Bettio:2021_6-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Bettio:2021_6-bibtex')">BibTeX</a></li>
    <div id="Bettio:2021_6-bibtex" style="display:none;">
    <pre class="collapse">@article{Bettio:2021_6,
  journal = {Computer Graphics Forum},
  title = {{A Novel Approach for Exploring Annotated Data With Interactive Lenses}},
  author = {Bettio, Fabio and Ahsan, Moonisa and Marton, Fabio and Gobbetti, Enrico},
  year = {2021},
  publisher = {The Eurographics Association and John Wiley & Sons Ltd.},
  issn = {1467-8659},
  url = { https://dspace.crs4.it/jspui/handle/1138/31},
  doi = {10.1111/cgf.14315}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1111/cgf.14315">10.1111/cgf.14315</a></li>
    
    
      <li><a href=" https://dspace.crs4.it/jspui/handle/1138/31">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="FRMMP:20"><span style="font-variant: small-caps">Fuentes Perez, L.J., Romero Calla, L.A., Montenegro, A.A., Mura, C., and Pajarola, R.</span> 2020. A Robust Feature-aware Sparse Mesh Representation. <i>Proceedings of Pacific Graphics Short Papers</i>, 25–30.</span>

<div id="FRMMP:20-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('FRMMP:20-bibtex')">BibTeX</a></li>
    <div id="FRMMP:20-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{FRMMP:20,
  author = {Fuentes Perez, Lizeth J. and Romero Calla, Luciano A. and Montenegro, Anselmo A. and Mura, Claudio and Pajarola, Renato},
  booktitle = {Proceedings of Pacific Graphics Short Papers},
  doi = {https://doi.org/10.2312/pg.20201226},
  url = {https://www.zora.uzh.ch/id/eprint/193666/},
  keywords = {graphics, geometry processing},
  pages = {25--30},
  title = {A Robust Feature-aware Sparse Mesh Representation},
  year = {2020}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.2312/pg.20201226">https://doi.org/10.2312/pg.20201226</a></li>
    
    
      <li><a href="https://www.zora.uzh.ch/id/eprint/193666/">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Filoscia:2020"><span style="font-variant: small-caps">Filoscia, I., Alderighi, T., Giorgi, D., Malomo, L., Callieri, M., and Cignoni, P.</span> 2020. Optimizing Object Decomposition to Reduce Visual Artifacts in 3D Printing. <i>Computer Graphics Forum</i> <i>39</i>, 2, 423–434.</span>

<div id="Filoscia:2020-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#Filoscia:2020-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Filoscia:2020-bibtex')">BibTeX</a></li>
    <div id="Filoscia:2020-bibtex" style="display:none;">
    <pre class="collapse">@article{Filoscia:2020,
  author = {Filoscia, I. and Alderighi, T. and Giorgi, D. and Malomo, L. and Callieri, M. and Cignoni, P.},
  title = {Optimizing Object Decomposition to Reduce Visual Artifacts in 3D Printing},
  journal = {Computer Graphics Forum},
  volume = {39},
  number = {2},
  pages = {423-434},
  doi = {https://doi.org/10.1111/cgf.13941},
  url = {https://openportal.isti.cnr.it/doc?id=people______::9d51621aaa57ea79baa0ac0466002bf0},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13941},
  year = {2020}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1111/cgf.13941">https://doi.org/10.1111/cgf.13941</a></li>
    
    
      <li><a href="https://openportal.isti.cnr.it/doc?id=people______::9d51621aaa57ea79baa0ac0466002bf0">URL</a></li>
    
  </ul>

  <!--
  <p id="Filoscia:2020-abstract" class="collapse">Abstract We propose a method for the automatic segmentation of 3D objects into parts which can be individually 3D printed and then reassembled by preserving the visual quality of the final object. Our technique focuses on minimizing the surface affected by supports, decomposing the object into multiple parts whose printing orientation is automatically chosen. The segmentation reduces the visual impact on the fabricated model producing non-planar cuts that adapt to the object shape. This is performed by solving an optimization problem that balances the effects of supports and cuts, while trying to place both in occluded regions of the object surface. To assess the practical impact of the solution, we show a number of segmented, 3D printed and reassembled objects.</p>
  -->

</div></li>
<li><span id="Laccone:2020"><span style="font-variant: small-caps">Laccone, F., Malomo, L., Pérez, J., et al.</span> 2020. A bending-active twisted-arch plywood structure: computational design and fabrication of the FlexMaps Pavilion. <i>SN Applied Sciences</i> <i>2</i>, 9, 1505.</span>

<div id="Laccone:2020-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#Laccone:2020-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Laccone:2020-bibtex')">BibTeX</a></li>
    <div id="Laccone:2020-bibtex" style="display:none;">
    <pre class="collapse">@article{Laccone:2020,
  author = {Laccone, Francesco and Malomo, Luigi and P{\'e}rez, Jes{\'u}s and Pietroni, Nico and Ponchio, Federico and Bickel, Bernd and Cignoni, Paolo},
  da = {2020/08/12},
  date-added = {2020-11-11 9:21:41 PM +0100},
  date-modified = {2020-11-11 9:21:41 PM +0100},
  doi = {10.1007/s42452-020-03305-w},
  id = {Laccone2020},
  isbn = {2523-3971},
  journal = {SN Applied Sciences},
  number = {9},
  pages = {1505},
  title = {A bending-active twisted-arch plywood structure: computational design and fabrication of the FlexMaps Pavilion},
  ty = {JOUR},
  url = {https://openportal.isti.cnr.it/doc?id=people______::67e43779f306d8fc3f362f80a56265a1},
  volume = {2},
  year = {2020},
  bdsk-url-1 = {https://doi.org/10.1007/s42452-020-03305-w}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1007/s42452-020-03305-w">10.1007/s42452-020-03305-w</a></li>
    
    
      <li><a href="https://openportal.isti.cnr.it/doc?id=people______::67e43779f306d8fc3f362f80a56265a1">URL</a></li>
    
  </ul>

  <!--
  <p id="Laccone:2020-abstract" class="collapse">Bending-active structures are able to efficiently produce complex curved shapes from flat panels. The desired deformation of the panels derives from the proper selection of their elastic properties. Optimized panels, called FlexMaps, are designed such that, once they are bent and assembled, the resulting static equilibrium configuration matches a desired input 3D shape. The FlexMaps elastic properties are controlled by locally varying spiraling geometric mesostructures, which are optimized in size and shape to match specific bending requests, namely the global curvature of the target shape. The design pipeline starts from a quad mesh representing the input 3D shape, which defines the edge size and the total amount of spirals: every quad will embed one spiral. Then, an optimization algorithm tunes the geometry of the spirals by using a simplified pre-computed rod model. This rod model is derived from a non-linear regression algorithm which approximates the non-linear behavior of solid FEM spiral models subject to hundreds of load combinations. This innovative pipeline has been applied to the project of a lightweight plywood pavilion named FlexMaps Pavilion, which is a single-layer piecewise twisted arch that fits a bounding box of 3.90x3.96x3.25 meters. This case study serves to test the applicability of this methodology at the architectural scale. The structure is validated via FE analyses and the fabrication of the full scale prototype.</p>
  -->

</div></li>
<li><span id="PMGFPG:20b"><span style="font-variant: small-caps">Pintore, G., Mura, C., Ganovelli, F., Fuentes-Perez, L., Pajarola, R., and Gobbetti, E.</span> 2020. Automatic 3D Reconstruction of Structured Indoor Environments. <i>ACM SIGGRAPH Tutorials</i>.</span>

<div id="PMGFPG:20b-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('PMGFPG:20b-bibtex')">BibTeX</a></li>
    <div id="PMGFPG:20b-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{PMGFPG:20b,
  author = {Pintore, Giovanni and Mura, Claudio and Ganovelli, Fabio and Fuentes-Perez, Lizeth and Pajarola, Renato and Gobbetti, Enrico},
  booktitle = {ACM SIGGRAPH Tutorials},
  keywords = {graphics, architecture, 3D reconstruction, point cloud, scanning, indoor scene reconstruction, segmentation, floor plans},
  title = {Automatic {3D} Reconstruction of Structured Indoor Environments},
  url = {https://dspace.crs4.it/jspui/handle/1138/13},
  doi = {https://doi.org/10.1145/3388769.3407469},
  year = {2020}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1145/3388769.3407469">https://doi.org/10.1145/3388769.3407469</a></li>
    
    
      <li><a href="https://dspace.crs4.it/jspui/handle/1138/13">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="9191202"><span style="font-variant: small-caps">Banterle, F., Artusi, A., Moreo, A., and Carrara, F.</span> 2020. Nor-Vdpnet: A No-Reference High Dynamic Range Quality Metric Trained On Hdr-Vdp 2. <i>2020 IEEE International Conference on Image Processing (ICIP)</i>, 126–130.</span>

<div id="9191202-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('9191202-bibtex')">BibTeX</a></li>
    <div id="9191202-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{9191202,
  author = {Banterle, Francesco and Artusi, Alessandro and Moreo, Alejandro and Carrara, Fabio},
  booktitle = {2020 IEEE International Conference on Image Processing (ICIP)},
  title = {Nor-Vdpnet: A No-Reference High Dynamic Range Quality Metric Trained On Hdr-Vdp 2},
  year = {2020},
  volume = {},
  number = {},
  pages = {126-130},
  doi = {10.1109/ICIP40778.2020.9191202}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1109/ICIP40778.2020.9191202">10.1109/ICIP40778.2020.9191202</a></li>
    
    
  </ul>

  <!---->

</div></li>
<li><span id="Pintore:2020:SI3"><span style="font-variant: small-caps">Pintore, G., Mura, C., Ganovelli, F., Fuentes-Perez, L., Pajarola, R., and Gobbetti, E.</span> 2020. State-of-the-art in Automatic 3D Reconstruction of Structured Indoor Environments. <i>Computer Graphics Forum</i> <i>39</i>, 2.</span>

<div id="Pintore:2020:SI3-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#Pintore:2020:SI3-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Pintore:2020:SI3-bibtex')">BibTeX</a></li>
    <div id="Pintore:2020:SI3-bibtex" style="display:none;">
    <pre class="collapse">@article{Pintore:2020:SI3,
  author = {Pintore, Giovanni and Mura, Claudio and Ganovelli, Fabio and Fuentes-Perez, Lizeth and Pajarola, Renato and Gobbetti, Enrico},
  title = {State-of-the-art in Automatic 3D Reconstruction of Structured Indoor Environments},
  journal = {Computer Graphics Forum},
  volume = {39},
  number = {2},
  year = {2020},
  note = {To appear},
  doi = {https://doi.org/10.1111/cgf.14021},
  url = {https://dspace.crs4.it/jspui/handle/1138/12}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/https://doi.org/10.1111/cgf.14021">https://doi.org/10.1111/cgf.14021</a></li>
    
    
      <li><a href="https://dspace.crs4.it/jspui/handle/1138/12">URL</a></li>
    
  </ul>

  <!--
  <p id="Pintore:2020:SI3-abstract" class="collapse"> Creating high-level structured 3D models of real-world indoor scenes from captured data is a fundamental task which has important applications in many fields. Given the complexity and variability of interior environments and the need to cope with noisy and partial captured data, many open research problems remain, despite the substantial progress made in the past decade. In this survey, we provide an up-to-date integrative view of the field, bridging complementary views coming from computer graphics and computer vision. After providing a characterization of input sources, we define the structure of output models and the priors exploited to bridge the gap between imperfect sources and desired output. We then identify and discuss the main components of a structured reconstruction pipeline, and review how they are combined in scalable solutions working at the building level. We finally point out relevant research issues and analyze research trends. </p>
  -->

</div></li>
<li><span id="10.1007/978-3-030-58598-3_26"><span style="font-variant: small-caps">Pintore, G., Agus, M., and Gobbetti, E.</span> 2020. AtlantaNet: Inferring the 3D Indoor Layout from a Single 360 degree Image Beyond the Manhattan World Assumption. <i>Computer Vision – ECCV 2020</i>, Springer International Publishing, 432–448.</span>

<div id="10.1007/978-3-030-58598-3_26-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#10.1007/978-3-030-58598-3_26-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('10.1007/978-3-030-58598-3_26-bibtex')">BibTeX</a></li>
    <div id="10.1007/978-3-030-58598-3_26-bibtex" style="display:none;">
    <pre class="collapse">@inproceedings{10.1007/978-3-030-58598-3_26,
  author = {Pintore, Giovanni and Agus, Marco and Gobbetti, Enrico},
  editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  title = {AtlantaNet: Inferring the 3D Indoor Layout from a Single 360 degree Image Beyond the Manhattan World Assumption},
  booktitle = {Computer Vision -- ECCV 2020},
  year = {2020},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-030-58598-3_26},
  url = {https://dspace.crs4.it/jspui/handle/1138/14},
  address = {Cham},
  pages = {432--448},
  isbn = {978-3-030-58598-3}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1007/978-3-030-58598-3_26">10.1007/978-3-030-58598-3_26</a></li>
    
    
      <li><a href="https://dspace.crs4.it/jspui/handle/1138/14">URL</a></li>
    
  </ul>

  <!--
  <p id="10.1007/978-3-030-58598-3_26-abstract" class="collapse">We introduce a novel end-to-end approach to predict a 3D room layout from a single panoramic image. Compared to recent state-of-the-art works, our method is not limited to Manhattan World environments, and can reconstruct rooms bounded by vertical walls that do not form right angles or are curved – i.e., Atlanta World models. In our approach, we project the original gravity-aligned panoramic image on two horizontal planes, one above and one below the camera. This representation encodes all the information needed to recover the Atlanta World 3D bounding surfaces of the room in the form of a 2D room footprint on the floor plan and a room height. To predict the 3D layout, we propose an encoder-decoder neural network architecture, leveraging Recurrent Neural Networks (RNNs) to capture long-range geometric patterns, and exploiting a customized training strategy based on domain-specific knowledge. The experimental results demonstrate that our method outperforms state-of-the-art solutions in prediction accuracy, in particular in cases of complex wall layouts or curved wall footprints.</p>
  -->

</div></li>
<li><span id="Tausch:2020"><span style="font-variant: small-caps">Tausch, R., Domajnko, M., Ritz, M., Knuth, M., Santos, P., and Fellner, D.W.</span> 2020. Towards 3D Digitization in the GLAM (Galleries, Libraries, Archives, and Museums) Sector: Lessons Learned and Future Outlook. <i>IPSI Transactions on Internet Research</i> <i>16</i>, 1, 45–53.</span>

<div id="Tausch:2020-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Tausch:2020-bibtex')">BibTeX</a></li>
    <div id="Tausch:2020-bibtex" style="display:none;">
    <pre class="collapse">@article{Tausch:2020,
  author = {Tausch, Reimar and Domajnko, Matevz and Ritz, Martin and Knuth, Martin and Santos, Pedro and Fellner, Dieter W.},
  url = {http://publica.fraunhofer.de/documents/N-578457.html},
  journal = {IPSI Transactions on Internet Research},
  keywords = {{3D} data acquisition, {3D} scanning, path planning, next-best view planning, automation},
  month = jan,
  number = {1},
  pages = {45--53},
  title = {Towards 3D Digitization in the GLAM (Galleries, Libraries, Archives, and Museums) Sector: Lessons Learned and Future Outlook},
  volume = {16},
  year = {2020}
}
</pre>
    </div>-->

    
    
    
      <li><a href="http://publica.fraunhofer.de/documents/N-578457.html">URL</a></li>
    
  </ul>

  <!---->

</div></li>
<li><span id="Alderighi:2019"><span style="font-variant: small-caps">Alderighi, T., Malomo, L., Giorgi, D., Bickel, B., Cignoni, P., and Pietroni, N.</span> 2019. Volume-Aware Design of Composite Molds. <i>ACM Trans. Graph.</i> <i>38</i>, 4.</span>

<div id="Alderighi:2019-materials">
  <ul class="nav nav-pills">
    <!--
      <li><a data-toggle="collapse" href="#Alderighi:2019-abstract">Abstract</a></li>
    -->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Alderighi:2019-bibtex')">BibTeX</a></li>
    <div id="Alderighi:2019-bibtex" style="display:none;">
    <pre class="collapse">@article{Alderighi:2019,
  author = {Alderighi, Thomas and Malomo, Luigi and Giorgi, Daniela and Bickel, Bernd and Cignoni, Paolo and Pietroni, Nico},
  title = {Volume-Aware Design of Composite Molds},
  year = {2019},
  issue_date = {July 2019},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {38},
  number = {4},
  issn = {0730-0301},
  url = {https://openportal.isti.cnr.it/doc?id=people______::036b4ebf5bb0d906222ec4024e0535c3},
  doi = {10.1145/3306346.3322981},
  journal = {ACM Trans. Graph.},
  month = jul,
  articleno = {110},
  numpages = {12},
  keywords = {mold design, casting, fabrication}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1145/3306346.3322981">10.1145/3306346.3322981</a></li>
    
    
      <li><a href="https://openportal.isti.cnr.it/doc?id=people______::036b4ebf5bb0d906222ec4024e0535c3">URL</a></li>
    
  </ul>

  <!--
  <p id="Alderighi:2019-abstract" class="collapse">We propose a novel technique for the automatic design of molds to cast highly complex shapes. The technique generates composite, two-piece molds. Each mold piece is made up of a hard plastic shell and a flexible silicone part. Thanks to the thin, soft, and smartly shaped silicone part, which is kept in place by a hard plastic shell, we can cast objects of unprecedented complexity. An innovative algorithm based on a volumetric analysis defines the layout of the internal cuts in the silicone mold part. Our approach can robustly handle thin protruding features and intertwined topologies that have caused previous methods to fail. We compare our results with state of the art techniques, and we demonstrate the casting of shapes with extremely complex geometry.</p>
  -->

</div></li>
<li><span id="Celarek:2019"><span style="font-variant: small-caps">Celarek, A., Jakob, W., Wimmer, M., and Lehtinen, J.</span> 2019. Quantifying the Error of Light Transport Algorithms. <i>Computer Graphics Forum</i> <i>38</i>, 4, 111–121.</span>

<div id="Celarek:2019-materials">
  <ul class="nav nav-pills">
    <!---->

    <!--<li><a data-toggle="collapse" href="javascript:toggleDiv('Celarek:2019-bibtex')">BibTeX</a></li>
    <div id="Celarek:2019-bibtex" style="display:none;">
    <pre class="collapse">@article{Celarek:2019,
  author = {Celarek, A. and Jakob, W. and Wimmer, M. and Lehtinen, J.},
  title = {Quantifying the Error of Light Transport Algorithms},
  journal = {Computer Graphics Forum},
  year = {2019},
  volume = {38},
  number = {4},
  pages = {111-121},
  doi = {10.1111/cgf.13775},
  url = {https://repositum.tuwien.at/handle/20.500.12708/15941}
}
</pre>
    </div>-->

    
    
      <li>DOI: <a href="http://dx.doi.org/10.1111/cgf.13775">10.1111/cgf.13775</a></li>
    
    
      <li><a href="https://repositum.tuwien.at/handle/20.500.12708/15941">URL</a></li>
    
  </ul>

  <!---->

</div></li></ol>

        
      </section>

      <footer class="page__meta">
        
        


        

      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <!-- <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div> -->


<div class="page__footer-copyright">  
  <img src="/assets/images/flag_eu.jpg" height="80" width="53">
  &copy; 2023 EVOCATION: A MSCA-ITN. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.
</div>
      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
